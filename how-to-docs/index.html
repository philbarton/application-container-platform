


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.1.7">
    
    
      
        <title>How To's - Application Container Platform</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4c7052ca.min.css">
      
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    <body dir="ltr">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#how-tos" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="Application Container Platform" class="md-header-nav__button md-logo" aria-label="Application Container Platform">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Application Container Platform
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              How To's
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Application Container Platform" class="md-nav__button md-logo" aria-label="Application Container Platform">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Application Container Platform
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../index.html" title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../services.html" title="Services" class="md-nav__link">
      Services
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="https://gitlab.digital.homeoffice.gov.uk/acp-docs/acp-support/tree/master/release-notes/" title="Release Notes" class="md-nav__link">
      Release Notes
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        How To's
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="index.html" title="How To's" class="md-nav__link md-nav__link--active">
      How To's
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#create-an-artifactory-access-token" class="md-nav__link">
    Create an Artifactory access token
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kubernetes-pod-autoscaling" class="md-nav__link">
    Kubernetes Pod Autoscaling
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chisel" class="md-nav__link">
    Chisel
  </a>
  
    <nav class="md-nav" aria-label="Chisel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-working-example" class="md-nav__link">
    A Working Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#debug-issues-with-your-deployments" class="md-nav__link">
    Debug Issues with your deployments
  </a>
  
    <nav class="md-nav" aria-label="Debug Issues with your deployments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#debug-with-secrets" class="md-nav__link">
    Debug with secrets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-issues-with-your-deployments-to-the-platform" class="md-nav__link">
    Debugging issues with your deployments to the platform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-deployments" class="md-nav__link">
    Debugging deployments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-check-your-deployment-replicaset-and-pods-created-properly" class="md-nav__link">
    1. Check your deployment, replicaset and pods created properly
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-investigate-potential-issues-with-your-pods-this-is-most-likely" class="md-nav__link">
    2. Investigate potential issues with your pods (this is most likely)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-investigate-potential-issues-with-your-service" class="md-nav__link">
    3. Investigate potential issues with your service
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-investigate-potential-issues-with-ingress" class="md-nav__link">
    4. Investigate potential issues with ingress
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dms-migration" class="md-nav__link">
    DMS Migration
  </a>
  
    <nav class="md-nav" aria-label="DMS Migration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prerequisite" class="md-nav__link">
    Prerequisite
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dms-setup" class="md-nav__link">
    DMS Setup
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#downscaling-services-out-of-hours" class="md-nav__link">
    Downscaling Services Out Of Hours
  </a>
  
    <nav class="md-nav" aria-label="Downscaling Services Out Of Hours">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aws-rds-relational-database-service" class="md-nav__link">
    AWS RDS (Relational Database Service)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kubernetes-pods" class="md-nav__link">
    Kubernetes Pods
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#drone-how-to" class="md-nav__link">
    Drone How To
  </a>
  
    <nav class="md-nav" aria-label="Drone How To">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#install-drone-cli" class="md-nav__link">
    Install Drone CLI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activate-your-pipeline" class="md-nav__link">
    Activate your pipeline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configure-your-pipeline" class="md-nav__link">
    Configure your pipeline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#publishing-docker-images" class="md-nav__link">
    Publishing Docker images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deployments" class="md-nav__link">
    Deployments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-another-repo" class="md-nav__link">
    Using Another Repo
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#versioned-deployments" class="md-nav__link">
    Versioned deployments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#migrating-your-pipeline" class="md-nav__link">
    Migrating your pipeline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-in-docker" class="md-nav__link">
    Docker-in-Docker
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services" class="md-nav__link">
    Services
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variable-escaping" class="md-nav__link">
    Variable Escaping
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scanning-images-in-drone" class="md-nav__link">
    Scanning Images in Drone
  </a>
  
    <nav class="md-nav" aria-label="Scanning Images in Drone">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qas" class="md-nav__link">
    Q&amp;As
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aws-ecr-for-private-docker-images" class="md-nav__link">
    AWS ECR for Private Docker Images
  </a>
  
    <nav class="md-nav" aria-label="AWS ECR for Private Docker Images">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-a-docker-repository" class="md-nav__link">
    Creating a Docker Repository
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generating-access-credentials" class="md-nav__link">
    Generating Access Credentials
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accessing-a-docker-repository" class="md-nav__link">
    Accessing a Docker Repository
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pre-requisites" class="md-nav__link">
    Pre-Requisites
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-retrieve-an-authorisation-token" class="md-nav__link">
    Step 1: Retrieve an authorisation token
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-login-with-authorisation-token" class="md-nav__link">
    Step 2: Login with Authorisation Token
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pulling-pushing-images" class="md-nav__link">
    Pulling &amp; Pushing Images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#listing-images-housekeeping" class="md-nav__link">
    Listing Images &amp; Housekeeping
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#managing-image-deployments-via-drone-ci" class="md-nav__link">
    Managing Image Deployments via Drone CI
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-ingress" class="md-nav__link">
    Using Ingress
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../developer-docs/index.html" title="Developer Getting Started Guide" class="md-nav__link">
      Developer Getting Started Guide
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../newuser.html" title="New User Guide" class="md-nav__link">
      New User Guide
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../rbac.html" title="RBAC Guide" class="md-nav__link">
      RBAC Guide
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../external-addresses.html" title="ACP External IPs" class="md-nav__link">
      ACP External IPs
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../service-lifecycle.html" title="Service Lifecycle" class="md-nav__link">
      Service Lifecycle
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#create-an-artifactory-access-token" class="md-nav__link">
    Create an Artifactory access token
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kubernetes-pod-autoscaling" class="md-nav__link">
    Kubernetes Pod Autoscaling
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chisel" class="md-nav__link">
    Chisel
  </a>
  
    <nav class="md-nav" aria-label="Chisel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-working-example" class="md-nav__link">
    A Working Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#debug-issues-with-your-deployments" class="md-nav__link">
    Debug Issues with your deployments
  </a>
  
    <nav class="md-nav" aria-label="Debug Issues with your deployments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#debug-with-secrets" class="md-nav__link">
    Debug with secrets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-issues-with-your-deployments-to-the-platform" class="md-nav__link">
    Debugging issues with your deployments to the platform
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-deployments" class="md-nav__link">
    Debugging deployments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-check-your-deployment-replicaset-and-pods-created-properly" class="md-nav__link">
    1. Check your deployment, replicaset and pods created properly
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-investigate-potential-issues-with-your-pods-this-is-most-likely" class="md-nav__link">
    2. Investigate potential issues with your pods (this is most likely)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-investigate-potential-issues-with-your-service" class="md-nav__link">
    3. Investigate potential issues with your service
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-investigate-potential-issues-with-ingress" class="md-nav__link">
    4. Investigate potential issues with ingress
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dms-migration" class="md-nav__link">
    DMS Migration
  </a>
  
    <nav class="md-nav" aria-label="DMS Migration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prerequisite" class="md-nav__link">
    Prerequisite
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dms-setup" class="md-nav__link">
    DMS Setup
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#downscaling-services-out-of-hours" class="md-nav__link">
    Downscaling Services Out Of Hours
  </a>
  
    <nav class="md-nav" aria-label="Downscaling Services Out Of Hours">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aws-rds-relational-database-service" class="md-nav__link">
    AWS RDS (Relational Database Service)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kubernetes-pods" class="md-nav__link">
    Kubernetes Pods
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#drone-how-to" class="md-nav__link">
    Drone How To
  </a>
  
    <nav class="md-nav" aria-label="Drone How To">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#install-drone-cli" class="md-nav__link">
    Install Drone CLI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activate-your-pipeline" class="md-nav__link">
    Activate your pipeline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configure-your-pipeline" class="md-nav__link">
    Configure your pipeline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#publishing-docker-images" class="md-nav__link">
    Publishing Docker images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deployments" class="md-nav__link">
    Deployments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-another-repo" class="md-nav__link">
    Using Another Repo
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#versioned-deployments" class="md-nav__link">
    Versioned deployments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#migrating-your-pipeline" class="md-nav__link">
    Migrating your pipeline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-in-docker" class="md-nav__link">
    Docker-in-Docker
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services" class="md-nav__link">
    Services
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variable-escaping" class="md-nav__link">
    Variable Escaping
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scanning-images-in-drone" class="md-nav__link">
    Scanning Images in Drone
  </a>
  
    <nav class="md-nav" aria-label="Scanning Images in Drone">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qas" class="md-nav__link">
    Q&amp;As
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aws-ecr-for-private-docker-images" class="md-nav__link">
    AWS ECR for Private Docker Images
  </a>
  
    <nav class="md-nav" aria-label="AWS ECR for Private Docker Images">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-a-docker-repository" class="md-nav__link">
    Creating a Docker Repository
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generating-access-credentials" class="md-nav__link">
    Generating Access Credentials
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accessing-a-docker-repository" class="md-nav__link">
    Accessing a Docker Repository
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pre-requisites" class="md-nav__link">
    Pre-Requisites
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-retrieve-an-authorisation-token" class="md-nav__link">
    Step 1: Retrieve an authorisation token
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-login-with-authorisation-token" class="md-nav__link">
    Step 2: Login with Authorisation Token
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pulling-pushing-images" class="md-nav__link">
    Pulling &amp; Pushing Images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#listing-images-housekeeping" class="md-nav__link">
    Listing Images &amp; Housekeeping
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#managing-image-deployments-via-drone-ci" class="md-nav__link">
    Managing Image Deployments via Drone CI
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-ingress" class="md-nav__link">
    Using Ingress
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  
                
                
                <h1 id="how-tos">How To's<a class="headerlink" href="#how-tos" title="Permanent link">#</a></h1>
<p>This tree contains a collection of how-to guides for Developers.</p>
<h2 id="create-an-artifactory-access-token">Create an Artifactory access token<a class="headerlink" href="#create-an-artifactory-access-token" title="Permanent link">#</a></h2>
<blockquote>
<p>Note: These instructions are intended for the ACP team. If you would like to request an Artifactory token, please raise the relevant support request via the <a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/30">Support Portal</a>.</p>
</blockquote>
<p>The requester should state the name of the token, how they would like to receive the token and post their GPG key.</p>
<ul>
<li>Create an <a href="https://docker.digital.homeoffice.gov.uk">Artifactory</a> access token using the following command:</li>
</ul>
<pre><code>curl -u&lt;username&gt;:&lt;api-key&gt; -XPOST &quot;https://artifactory.digital.homeoffice.gov.uk/artifactory/api/security/token&quot; -d &quot;username=&lt;robot-username&gt;&quot; -d &quot;scope=member-of-groups:&lt;appropriate-groups&gt;&quot; -d &quot;expires_in=0&quot;
</code></pre>

<p>where <code>&lt;robot-username&gt;</code> is the name of the access token and <code>&lt;appropriate-groups&gt;</code> is a comma separated list of the groups the token should be in (normally this will only be <code>ci</code>).</p>
<blockquote>
<p>Note: If you set the <code>expires_in</code> time higher than 0, you will not be able to revoke the token via the UI.</p>
</blockquote>
<ul>
<li>Once the token has been created, JSON data should be returned which will include the access key. The JSON data you receive will be the only time you will be able to see the access key as it is not shown on Artifactory. You should, however, be able to see the name and expiry date (if you set an expiry time) of the access key in the "Access Keys" section.</li>
</ul>
<h2 id="kubernetes-pod-autoscaling">Kubernetes Pod Autoscaling<a class="headerlink" href="#kubernetes-pod-autoscaling" title="Permanent link">#</a></h2>
<p>For full documentation on kubernetes autoscaling feature please go <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">here</a>. As of writing the ACP cluster supports standard autoscaling based on a CPU metric, there are however plans to support custom-metrics in the near future.</p>
<p>Assuming you have a deployment 'web' and you wish to autoscale the deployment when it hit's a 40% CPU usage with min/max of 5/10 pods.</p>
<pre><code class="YAML">apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: web
spec:
  maxReplicas: 10
  minReplicas: 5
  scaleTargetRef:
    apiVersion: extensions/v1beta1
    kind: Deployment
    name: web
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 50
</code></pre>

<p><strong>Sysdig Metrics - Experimental</strong></p>
<p>The autoscaler can also consume and make scaling decisions from <a href="https://sysdig.digital.homeoffice.gov.uk">sysdig</a> metrics. Note, this feature is currently experimental but tested as working.</p>
<p>An example of sysdig would be scaling on http_request</p>
<pre><code class="YAML">apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: autoscaler
spec:
  scaleTargetRef:
    apiVersion: extensions/v1beta1
    kind: Deployment
    name: myapplication
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Object
    object:
      target:
        kind: Service
        name: myservice
      metricName: net.http.request.count
      targetValue: 100
</code></pre>

<h2 id="chisel">Chisel<a class="headerlink" href="#chisel" title="Permanent link">#</a></h2>
<blockquote>
<p><em>The Problem</em>: we want to provide services running in ACP access to the third party services as well as the ability to have user-based access controls. At present network access in ACP is provided via Calico, but this becomes redundant when the traffic egresses the cluster. Simply peering networks together either through VPC peering or VPN connections doesn't provide the controls we want. We could rely on user-authentication on third-party service but not all services are authenticated (take POISE) and beyond that peering networks provides no means of auditing traffic that is traversing the bridged networks.</p>
</blockquote>
<p>One pattern we are exploring is the use of a proxy cluster with an authenticated side-kick to route traffic and provide end-to-end encryption. Both ACP Notprod and Prod are peered to an respective proxy cluster that is running a <a href="https://github.com/jpillora/chisel">Chisel</a> server. Below is rough idea of how the chisel service works.</p>
<p><img alt="alt text" src="https://github.com/UKHomeOffice/application-container-platform/blob/master/docs/how-to-docs/pics/chisel.png" title="Chisel" /></p>
<p>The workflow for this is as follows, note the following example is assuming we have peered with a network in the proxy cluster which is exposing x services.</p>
<ul>
<li>A request via BAU the provisioning of a service on the Chisel server.</li>
<li>Once done user is provided credentials for service.</li>
<li>You add into your deployment a chisel container running in client mode and add the configuration as described to route the traffic. In regard to DNS and hostnames, kubernetes pods permit the user to add host entries into the container DNS, enabling you to override.</li>
<li>The traffic is picked up, encrypted over an ssh tunnel and pushed to the Chisel server where the user credentials are evaluated. Assuming everything is ok the traffic is then proxied on to destination.</li>
</ul>
<h4 id="a-working-example">A Working Example<a class="headerlink" href="#a-working-example" title="Permanent link">#</a></h4>
<p>We have a two services called <code>example-api.internal.homeoffice.gov.uk</code> and <code>another-service.example.com</code> and we wish to consume the API from the pods. Lets assume the service has already been provisioned on the Chisel server and we have the credentials at hand.</p>
<pre><code class="YAML">kind: Deployment
metadata:
  name: consumer
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: consumer
    spec:
      hostAliases:
      - hostnames:
        - another-service.example.com
        - example-api.internal.homeoffice.gov.uk
        ip: 127.0.0.1
      securityContext:
        fsGroup: 1000
      volumes:
      - name: bundle
        configMap:
          name: bundle
      containers:
      - name: consumer
        image: quay.io/ukhomeofficedigital/someimage:someversion
      - name: chisel
        image: quay.io/ukhomeofficedigital/chisel:v1.3.1 # Both Chisel Client &amp; Server versions must match
        securityContext:
          runAsNonRoot: true
        env:
        # essentially user:password
        - name: AUTH
          valueFrom:
            secretKeyRef:
              name: chisel
              key: chisel.auth
        # this optional BUT recommended this is fingerprint for the SSH service
        - name: CHISEL_KEY
          valueFrom:
            secretKeyRef:
              name: chisel
              key: chisel.key
        args:
        - client
        - -v
        # this the chisel endpoint service hostname
        - gateway-internal.px.notprod.acp.homeoffice.gov.uk:443
        # this is saying listen on port 10443 and route all traffic to another-service.example.com:443 endpoint
        - 127.0.0.1:10443:another-service.example.com:443
        - 127.0.0.1:10444:example-api.internal.homeoffice.gov.uk:443
        volumeMounts:
        - name: bundle
          mountPath: /etc/ssl/certs
          readOnly: true
</code></pre>

<p>The above embeds the sidekick into the Pod and requests the client to listen on localhost:10443 and 10444 to redirect traffic via the Chisel service. The one annoying point here is the port requirements, placing things on different ports, but unfortunately this is required. You should be able to call the service via <code>curl https://another-service.example.com:10443</code> at this point.</p>
<h2 id="debug-issues-with-your-deployments">Debug Issues with your deployments<a class="headerlink" href="#debug-issues-with-your-deployments" title="Permanent link">#</a></h2>
<h4 id="debug-with-secrets">Debug with secrets<a class="headerlink" href="#debug-with-secrets" title="Permanent link">#</a></h4>
<p>Sometimes your app doesn't want to talk to an API or a DB and you've stored the credentials or just the details of that in secret.</p>
<p>The following approaches can be used to validate that your secret is set correctly</p>
<pre><code class="bash">$ kubectl exec -ti my-pod -c my-container -- mysql -h\$DBHOST -u\$DBUSER -p\$DBPASS
## or
$ kubectl exec -ti my-pod -c my-container -- openssl verify /secrets/certificate.pem
## or
$ kubectl exec -ti my-pod -c my-container bash
## and you'll naturally have all the environment variables set and volumes mounted.
## however we recommend against outputing them to the console e.g. echo $DBHOST
## instead if you want to assert a variable is set correctly use
$ [[ -z $DBHOST ]]; echo $?
## if it returns 1 then the variable is set.
</code></pre>

<h4 id="debugging-issues-with-your-deployments-to-the-platform">Debugging issues with your deployments to the platform<a class="headerlink" href="#debugging-issues-with-your-deployments-to-the-platform" title="Permanent link">#</a></h4>
<p>If you get to the end of the above guide but can't access your application there are a number of places something could be going wrong.
This section of the guide aims to give you some basic starting points for how to debug your application.</p>
<h4 id="debugging-deployments">Debugging deployments<a class="headerlink" href="#debugging-deployments" title="Permanent link">#</a></h4>
<p>We suggest the following steps:</p>
<h4 id="1-check-your-deployment-replicaset-and-pods-created-properly">1. Check your deployment, replicaset and pods created properly<a class="headerlink" href="#1-check-your-deployment-replicaset-and-pods-created-properly" title="Permanent link">#</a></h4>
<pre><code class="bash">$ kubectl get deployments
$ kubectl get rs
$ kubectl get pods
</code></pre>

<h4 id="2-investigate-potential-issues-with-your-pods-this-is-most-likely">2. Investigate potential issues with your pods (this is most likely)<a class="headerlink" href="#2-investigate-potential-issues-with-your-pods-this-is-most-likely" title="Permanent link">#</a></h4>
<p>If the get pods command shows that your pods aren't all running then this is likely where the issue is. You can then try curling your application to see if it is alive and responding as expected. e.g.</p>
<pre><code class="bash">$ curl localhost:4000
</code></pre>

<p>You can get further details on why the pods couldn't be deployed by running:</p>
<pre><code class="bash">$ kubectl describe pods *pods_name_here*
</code></pre>

<p>If your pods are running you can check they are operating as expected by <code>exec</code>ing into them (this gets you a shell on one of your containers).</p>
<pre><code class="bash">$ kubectl exec -ti *pods_name_here* -c *container_name_here* /bin/sh
</code></pre>

<blockquote>
<p><strong>Please note</strong> that the <code>-c</code> argument isn't needed if there is only one container in the pod.*</p>
</blockquote>
<h4 id="3-investigate-potential-issues-with-your-service">3. Investigate potential issues with your service<a class="headerlink" href="#3-investigate-potential-issues-with-your-service" title="Permanent link">#</a></h4>
<p>A good way to do this is to run a container in your namespace with a bash terminal:</p>
<pre><code class="bash">$ kubectl run -ti --image quay.io/ukhomeofficedigital/centos-base debugger bash
</code></pre>

<p>From this container you can then try curling your service. Your service will have a nice DNS name by default, so you can for example run:</p>
<pre><code class="bash">$ curl my-service-name
</code></pre>

<h4 id="4-investigate-potential-issues-with-ingress">4. Investigate potential issues with ingress<a class="headerlink" href="#4-investigate-potential-issues-with-ingress" title="Permanent link">#</a></h4>
<p>Minikube runs an ingress service using nginx. It's possible to ssh into the nginx container and cat the <code>nginx.conf</code> to inspect the configuration for nginx.</p>
<p>In order to attach to the nginx container, you need to know the name of the container:</p>
<pre><code class="shell">$ kubectl get pods
NAME                               READY     STATUS    RESTARTS   AGE
default-http-backend-2kodr         1/1       Running   1          5d
acp-hello-world-3757754181-x1kdu   1/1       Running   2          6d
ingress-3879072234-5f4uq           1/1       Running   2          5d
</code></pre>

<p>You can attach to the running container with:</p>
<pre><code class="bash">$ kubectl exec -ti &lt;ingress-3879072234-5f4uq&gt; -c &lt;proxy&gt; bash
</code></pre>

<p>where <code>&lt;proxy&gt;</code> is the container name of the nginx proxy inside the pod. You can find the name by describing the pod.</p>
<p>You're inside the container. You can cat the <code>nginx.conf</code> with:</p>
<pre><code class="bash">$ cat /etc/nginx/nginx.conf
</code></pre>

<p>You can also inspect the logs with:</p>
<pre><code class="bash">$ kubectl logs &lt;ingress-3879072234-5f4uq&gt;
</code></pre>

<h2 id="dms-migration">DMS Migration<a class="headerlink" href="#dms-migration" title="Permanent link">#</a></h2>
<h4 id="prerequisite"><strong>Prerequisite</strong><a class="headerlink" href="#prerequisite" title="Permanent link">#</a></h4>
<p>The following need to be true before you follow this guide:
* AWS console logon
* Access to the DMS service from console
* A region where STS has been activated</p>
<h4 id="dms-setup"><strong>DMS Setup</strong><a class="headerlink" href="#dms-setup" title="Permanent link">#</a></h4>
<p>Login to the AWS console using your auth, switch to a role with the correct access policies and verify you're in the right region. Next, select DMS from the services on the main dashboard to access the data migration home screen. Under the "Get started" section click on the "create migration" button then next to the Replication instance. You should see the following screen:</p>
<p><img alt="Alt text" src="pics/dms-doc-1.png?raw=true" /></p>
<p>The following are the options and example answers for the replication instance:</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Example answer</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>dev-team-dms</td>
<td>A name for the replication image. This name should be unique.</td>
</tr>
<tr>
<td>Description</td>
<td>DMS instance for migration</td>
<td>Brief description of the instance</td>
</tr>
<tr>
<td>Instance class</td>
<td>dms.t2.medium</td>
<td>The class of replication resource with the configuration you need for your migration.</td>
</tr>
<tr>
<td>VPC</td>
<td>vpc-*</td>
<td>The virtual private cloud resource where you wish to add your dms instance. This should be as close to both the source and target instance as possible.</td>
</tr>
<tr>
<td>Multi-AZ</td>
<td>No</td>
<td>Optional parameter to create a standby replica of your replication instance in another Availability Zone. Used for failover.</td>
</tr>
<tr>
<td>Publicly Accessible</td>
<td>False</td>
<td>Option to access your instance from the internet</td>
</tr>
</tbody>
</table>
<p>You won't need to set any of the advanced settings. To create the instance click on the next button. You should now see a screen like this:</p>
<p><img alt="Alt text" src="pics/dms-doc-2.png?raw=true" /></p>
<p>The following are the options and example answers for the endpoints instances:</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Example answer</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Endpoint identifer</td>
<td>database-source/target</td>
<td>This is the name you use to identify the endpoint.</td>
</tr>
<tr>
<td>Source/target engine</td>
<td>postgres</td>
<td>Choose the type of database engine that for this endpoint.</td>
</tr>
<tr>
<td>Server name</td>
<td>mysqlsrvinst.abcd123456789.us-west-1.rds.amazonaws.com</td>
<td>Type of server name. For an on-premises database, this can be the IP address or the public hostname. For an Amazon RDS DB instance, this can be the endpoint for the DB instance.</td>
</tr>
<tr>
<td>Port</td>
<td>5432</td>
<td>The port used by the database.</td>
</tr>
<tr>
<td>SSL mode</td>
<td>None</td>
<td>SSL mode for encryption for your endpoints.</td>
</tr>
<tr>
<td>Username</td>
<td>root</td>
<td>The user name with the permissions required to allow data migration.</td>
</tr>
<tr>
<td>Password</td>
<td><strong><em>*</em></strong>*</td>
<td>The password for the account with the required permissions.</td>
</tr>
<tr>
<td>Database Name (target)</td>
<td>dev-db</td>
<td>The name of the attached database to the selected endpoint.</td>
</tr>
</tbody>
</table>
<p>Repeat these options for both source and target and make sure to test connection before clicking next. You might need to append security group rules to allow the replication instance access, for example:</p>
<p>Replication instance has internal ip address 10.20.0.0 and the RDS is on port 5432 and uses TCP. Append rule</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Procol</th>
<th>Port Range</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>Custom TCP rule</td>
<td>TCP</td>
<td>5432</td>
<td>Custom 10.20.0.0/32</td>
</tr>
</tbody>
</table>
<p>Once this has fully been setup click next and you should be able to view the tasks page:</p>
<p><img alt="Alt text" src="pics/dms-doc-3.png?raw=true" />
<img alt="Alt text" src="pics/dms-doc-4.png?raw=true" /></p>
<p>The following are the options and example answers for these tasks:</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Example answer</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Task name</td>
<td>Migration-task</td>
<td>A name for the task.</td>
</tr>
<tr>
<td>Task Description</td>
<td>Task for migrating</td>
<td>A description for the task.</td>
</tr>
<tr>
<td>Source endpoint</td>
<td>source-instance</td>
<td>The source endpoint for migration.</td>
</tr>
<tr>
<td>Target endpoint</td>
<td>target-instance</td>
<td>The target endpoint for migration.</td>
</tr>
<tr>
<td>Replication instance</td>
<td>replication-instance</td>
<td>The replication instance to be used.</td>
</tr>
<tr>
<td>Migration type</td>
<td>Migrate existing data</td>
<td>Migration method you want to use.</td>
</tr>
<tr>
<td>Start task on create</td>
<td>True</td>
<td>When selected the task begins as soon as it is created.</td>
</tr>
<tr>
<td>Target table preparation</td>
<td>Drop table on target</td>
<td>Migration strategy on target.</td>
</tr>
<tr>
<td>Include LOB columns in replication</td>
<td>Limited LOB mode</td>
<td>Migration of large objects on target.</td>
</tr>
<tr>
<td>Max LOB size</td>
<td>32 kb</td>
<td>Maximum size of large objects.</td>
</tr>
<tr>
<td>Enable logging</td>
<td>False</td>
<td>When selected migration events are logged.</td>
</tr>
</tbody>
</table>
<p>After completion the job will automatically run if "start task on create" has been selected. If not, the job can be started in the tasks section by selecting it and clicking on the "Start/Resume" button.</p>
<h2 id="downscaling-services-out-of-hours">Downscaling Services Out Of Hours<a class="headerlink" href="#downscaling-services-out-of-hours" title="Permanent link">#</a></h2>
<p>In an effort to reduce costs on running the platform, we've enabled the capability to scale down specific resources Out Of Hours (OOH) for Non-Production and Production environments.</p>
<h4 id="aws-rds-relational-database-service">AWS RDS (Relational Database Service)<a class="headerlink" href="#aws-rds-relational-database-service" title="Permanent link">#</a></h4>
<p>RDS resources can be transitioned to a stopped state OOH to save on resource utilisation costs. This is currently managed with the use of tags on the RDS instance defining a cronjob schedule to stop and start the instance.</p>
<p>To set a schedule for your RDS instances, please use the related <a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/95">Support Portal support request template</a>.</p>
<blockquote>
<p><strong>Note:</strong> Shutting down an RDS instance will have cost savings based on the instance size, however you will still be charged for the allocated storage.</p>
</blockquote>
<h4 id="kubernetes-pods">Kubernetes Pods<a class="headerlink" href="#kubernetes-pods" title="Permanent link">#</a></h4>
<p>Automatically scale down Kubernetes Deployments &amp; Statefulsets to 0 replicas during non-working hours for Non-Production or Production Environments.</p>
<p>Downscaling for Deployments &amp; Statefulsets are managed by an annotation set within the manifest, and are processed every 30 seconds for changes, by a service running within the Kubernetes Clusters.</p>
<h5>Usage</h5>
<p>Set <strong>ONE</strong> of the following annotations on your Deployment / Statefulset:
- <code>downscaler/uptime</code>: A time schedule in which the Deployment should be scaled up
- <code>downscaler/downtime</code>: A time schedule in which the Deployment should be scaled down to 0 replicas</p>
<p>The annotation values for the timeframe must have the following format to be processed correctly: <code>&lt;WEEKDAY-FROM&gt;-&lt;WEEKDAY-TO-INCLUSIVE&gt; &lt;HH&gt;:&lt;MM&gt;-&lt;HH&gt;:&lt;MM&gt; &lt;TIMEZONE&gt;</code></p>
<p>For example, to schedule a Deployment to only run on weekdays during working hours, the following annotation would be set: <code>downscaler/uptime: Mon-Fri 09:00-17:30 Europe/London</code></p>
<blockquote>
<p><strong>Note:</strong> When the deployment is downscaled, an additional annotation <code>downscaler/original-replicas</code> is automatically set to retain a history of the desired replicas prior to the downscale action. If this annotation has been deleted before the service is automatically scaled back up, the downscaler service will not know what to set the replicas back to, and so it won't attempt to scale up the resource.</p>
</blockquote>
<p><strong>Example Spec:</strong></p>
<pre><code class="yml">apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    downscaler/uptime: Mon-Fri 09:00-17:30 Europe/London
  labels:
    name: example-app
  name: example-app
  namespace: acp-example
spec:
  replicas: 2
  template:
    spec:
      containers:
        image: docker.digital.homeoffice.gov.uk/acp-example-app:v0.0.1@sha256:07397c41ac25c4b19e0485006849201f04168703f0016fad75b8ba5d9885d6d4
...
</code></pre>

<h2 id="drone-how-to">Drone How To<a class="headerlink" href="#drone-how-to" title="Permanent link">#</a></h2>
<h4 id="install-drone-cli">Install Drone CLI<a class="headerlink" href="#install-drone-cli" title="Permanent link">#</a></h4>
<ul>
<li>Github drone instance: https://drone.acp.homeoffice.gov.uk/</li>
<li>Gitlab drone instance: https://drone-gitlab.acp.homeoffice.gov.uk/</li>
</ul>
<p>Download and install the <a href="https://0-8-0.docs.drone.io/cli-installation/">Drone CLI</a>.</p>
<blockquote>
<p>At the time of writing, we are using version 0.8 of Drone.</p>
</blockquote>
<p>You can also install a release from <a href="https://github.com/drone/drone-cli/releases">Drone CLI's GitHub repo</a>.
Once you have downloaded the relevant file, extract it and move it to the <code>/usr/local/bin</code> directory.</p>
<p>Verify it works as expected:</p>
<pre><code class="bash">$ drone --version
drone version 0.8.0
</code></pre>

<p>Export the <code>DRONE_SERVER</code> and <code>DRONE_TOKEN</code> variables. You can find your token on Drone by clicking the icon in the top right corner and going to <a href="https://drone.acp.homeoffice.gov.uk/account/token">Token</a>.</p>
<pre><code class="bash">export DRONE_SERVER=https://drone.acp.homeoffice.gov.uk
export DRONE_TOKEN=&lt;your_drone_token&gt;
</code></pre>

<p>If your installation is successful, you should be able to query the current Drone instance:</p>
<pre><code class="bash">$ drone info
User: youruser
Email: youremail@gmail.com
</code></pre>

<blockquote>
<p>If the output is</p>
<p><code>bash
Error: you must provide the Drone server address.</code></p>
<p>or</p>
<p><code>Error: you must provide your Drone access token.</code></p>
<p>Please make sure that you have exported the <code>DRONE_SERVER</code> and <code>DRONE_TOKEN</code> variables properly.</p>
</blockquote>
<h4 id="activate-your-pipeline">Activate your pipeline<a class="headerlink" href="#activate-your-pipeline" title="Permanent link">#</a></h4>
<p>Once you are logged in to Drone, you will find a list of repos by clicking the icon in the top right corner and going to <a href="https://drone.acp.homeoffice.gov.uk/account/repos">Repositories</a>.</p>
<p>Sync your repository access rights with Drone by clicking the icon in the top right corner again with the <code>Synchronize</code> button - this needs to be applied everytime when a new repository is created.</p>
<p>Select the repo you want to activate.</p>
<p>Navigate to your repository's settings in Github (or Gitlab) and you will see a webhook has been created. You need to update the url for the newly created web hook so that it matches this pattern:</p>
<pre><code>https://drone-external.acp.homeoffice.gov.uk/hook?access_token=some_token
</code></pre>

<blockquote>
<p>If it is already in that format there is no need to change anything.</p>
<p>The token in the payload url will not be the same as the personal token that you exported and it should be left unchanged.</p>
<p><strong>Please note that this does not apply to Gitlab. When you activate the repo in Drone, you should not change anything for a Gitlab repo.</strong></p>
</blockquote>
<h4 id="configure-your-pipeline">Configure your pipeline<a class="headerlink" href="#configure-your-pipeline" title="Permanent link">#</a></h4>
<p>In the root folder of your project, create a <code>.drone.yml</code> file with the following content:</p>
<pre><code class="yaml">pipeline:

  my-build:
    image: docker:18.03
    environment:
      - DOCKER_HOST=tcp://172.17.0.1:2375
    commands:
      - docker build -t &lt;image_name&gt; .
    when:
      branch: master
      event: push
</code></pre>

<p>Commit and push your changes:</p>
<pre><code class="bash">$ git add .drone.yml
$ git commit
$ git push origin master
</code></pre>

<blockquote>
<p><strong>Please note</strong> you should replace the name &lt;...&gt; with the name of your app.</p>
</blockquote>
<p>You should be able to watch your build succeed in the Drone UI.</p>
<h4 id="publishing-docker-images">Publishing Docker images<a class="headerlink" href="#publishing-docker-images" title="Permanent link">#</a></h4>
<h5>Publishing to Quay</h5>
<p>If your repository is hosted on Gitlab, you don't want to publish your images to Quay. Images published to Quay are public and can be inspected and downloaded by anyone. <a href="#publishing-to-artifactory">You should publish your private images to Artifactory</a>.</p>
<p>Register for a free <a href="https://quay.io">Quay account</a> using your Github account linked to the Home Office organisation.</p>
<p>Once you've logged into Quay check that you have <code>ukhomeofficedigital</code> under Users and Organisations.
If you do not, <a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/88">submit a support request on the support portal for access to the ukhomeoffice organisation</a>.</p>
<p>Once you have access to view the <code>ukhomeofficedigital</code> repositories, click repositories and
click the <code>+ Create New Repositories</code> that is:</p>
<ul>
<li>public</li>
<li>empty - no need to create a repo from a Dockerfile or link it to an existing repository</li>
</ul>
<p>Add your project to the UKHomeOffice Quay account and <a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/37">submit a support request on the support portal for a new Quay robot</a>.</p>
<p>Add the step to publish the docker image to Quay in your Drone pipeline:</p>
<pre><code class="yaml">image_to_quay:
  image: quay.io/ukhomeofficedigital/drone-docker
  secrets:
    - docker_password
  environment:
    - DOCKER_USERNAME=ukhomeofficedigital+&lt;your_robot_username&gt;
  registry: quay.io
  repo: quay.io/ukhomeofficedigital/&lt;your_quay_repo&gt;
  tags:
    - ${DRONE_COMMIT_SHA}
    - latest
  when:
    branch: master
    event: push
</code></pre>

<p>Where <code>&lt;your_quay_repo&gt;</code> in:</p>
<pre><code class="yaml">quay.io/ukhomeofficedigital/&lt;your_quay_repo&gt;
</code></pre>

<p>is the name of the Quay repo you (should) have already created.</p>
<blockquote>
<p>Note: ${DRONE_COMMIT_SHA} is a Drone environment variable that is passed to the container at runtime.</p>
</blockquote>
<p>The build should fail with the following error:</p>
<pre><code class="bash">Error response from daemon: Get https://quay.io/v2/: unauthorized: Could not find robot with username: ukhomeofficedigital+&lt;your_robot_username&gt; and supplied password.
</code></pre>

<p>The error points to the missing password for the Quay robot. You will need to add this as a drone secret.</p>
<p>You can do this through the Drone UI by going to your repo, clicking the menu icon in the top right and then clicking <strong>Secrets</strong>. You should be presented with a list of the secrets for that repo (if there are any) and you should be able to add secrets giving them a name and value. Add a secret with the name <code>DOCKER_PASSWORD</code> and with the value being the robot token that was supplied to you.</p>
<p>Alternatively, you can use the Drone CLI to add the secret:</p>
<pre><code>$ drone secret add --repository ukhomeoffice/&lt;your_github_repo&gt; --name DOCKER_PASSWORD --value &lt;your_robot_token&gt;
</code></pre>

<p>Restarting the build should be enough to make it pass.</p>
<blockquote>
<p>The Drone CLI allows for more control over the secret as opposed to the UI. For example, the CLI allows you to specify the image and the events that the secret will be allowed to be used with.</p>
<p>Also note that the secret was specified in the <code>secrets</code> section of the pipeline to give it access to the secret. Without this, the pipeline would not be able to use the secret and it would fail. Secrets in this section are automatically uppercased at runtime so it is important that the secret is uppercased in your commands.</p>
</blockquote>
<p>You can also push specifically tagged images by using the <code>DRONE_TAG</code> Drone environment variable and by using the <code>tag</code> event:</p>
<pre><code class="yaml">tagged_image_to_quay:
  image: quay.io/ukhomeofficedigital/drone-docker
  secrets:
    - docker_password
  environment:
    - DOCKER_USERNAME=ukhomeofficedigital+&lt;your_robot_username&gt;
  registry: quay.io
  repo: quay.io/ukhomeofficedigital/&lt;your_quay_repo&gt;
  tags:
    - ${DRONE_TAG}
  when:
    event: tag
</code></pre>

<p>Tag using <code>git tag v1.0</code> and push your tag with <code>git push origin v1.0</code> (replace <code>v1.0</code> with the tag you actually want to use).</p>
<blockquote>
<p>Note: These pipeline configurations are using the Docker plugin for Drone. For more information, see http://plugins.drone.io/drone-plugins/drone-docker/</p>
</blockquote>
<h5>Publishing to Artifactory</h5>
<p>Images hosted on <a href="https://docker.digital.homeoffice.gov.uk">Artifactory</a> are private.</p>
<p>If your repository is hosted publicly on GitHub, you shouldn't publish your images to Artifactory. Artifactory is only used to publish private images. <a href="#publishing-to-quay">You should use Quay to publish your public images</a>.</p>
<p><a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/30">Submit a support request for a new Artifactory access token</a>. You should be supplied an access token in response.</p>
<p>You can inject the token that has been supplied to you with:</p>
<pre><code>$ drone secret add --repository &lt;gitlab_repo_group&gt;/&lt;your_gitlab_repo&gt; --name DOCKER_PASSWORD --value &lt;your_robot_token&gt;
</code></pre>

<p>You can add the following step in your <code>.drone.yml</code>:</p>
<pre><code class="yaml">image_to_artifactory:
  image: quay.io/ukhomeofficedigital/drone-docker
  secrets:
    - docker_password
  environment:
    - DOCKER_USERNAME=&lt;your_robots_username&gt;
  registry: docker.digital.homeoffice.gov.uk
  repo: docker.digital.homeoffice.gov.uk/&lt;your_artifactory_repo&gt;
  tags:
    - ${DRONE_COMMIT_SHA}
    - latest
  when:
    branch: master
    event: push
</code></pre>

<p>Where the <code>&lt;image_name&gt;</code> in:</p>
<pre><code class="yaml">docker tag &lt;image_name&gt; docker.digital.homeoffice.gov.uk/ukhomeofficedigital/&lt;your_artifactory_repo&gt;:$${DRONE_COMMIT_SHA}
</code></pre>

<p>is the name of the image you tagged previously in the build step.</p>
<p>The image should now be published on Artifactory. Please note that we regularly remove container images that have not been downloaded in a year.</p>
<h4 id="deployments">Deployments<a class="headerlink" href="#deployments" title="Permanent link">#</a></h4>
<h5>Deployments and promotions</h5>
<p>Create a step that runs only on deployments:</p>
<pre><code class="yaml">deploy-to-preprod:
  image: busybox
  commands:
    - /bin/echo hello preprod
  when:
    environment: preprod
    event: deployment
</code></pre>

<p>Push the changes to your remote repository.</p>
<p>You can deploy the build you just pushed with the following command:</p>
<pre><code class="bash">$ drone deploy ukhomeoffice/&lt;your_repo&gt; 16 preprod
</code></pre>

<p>Where <code>16</code> is the successful build number on drone that you wish to deploy to the <code>preprod</code> environment.</p>
<p>You can pass additional parameters to your deployment as environment variables:</p>
<pre><code class="bash">$ drone deploy ukhomeoffice/&lt;your_repo&gt; 16 preprod -p DEBUG=1 -p NAME=Dan
</code></pre>

<p>and use them in the step like this:</p>
<pre><code class="yaml">deploy-to-preprod:
  image: busybox
  commands:
    - /bin/echo hello $${NAME}
  when:
    environment: preprod
    event: deployment
</code></pre>

<p>Environments are strings and can be set to any value. When you wish to deploy to several environments you can create a step for each one of them:</p>
<pre><code class="yaml">deploy-to-preprod:
  image: busybox
  commands:
    - /bin/echo hello preprod
  when:
    environment: preprod
    event: deployment

deploy-to-prod:
  image: busybox
  commands:
    - /bin/echo hello prod
  when:
    environment: prod
    event: deployment
</code></pre>

<p>And deploy them accordingly:</p>
<pre><code class="bash">$ drone deploy ukhomeoffice/&lt;your_repo&gt; 16 preprod
$ drone deploy ukhomeoffice/&lt;your_repo&gt; 16 prod
</code></pre>

<p>Read more on <a href="http://0-8-0.docs.drone.io/environment/">environments</a>.</p>
<h5>Drone as a Pull Request builder</h5>
<p>Drone pipelines are triggered when events occurs. Event triggers can be as simple as a <em>push</em>, <em>a tagged commit</em>, <em>a pull request</em> or as granular as <em>only for pull requests for a branch named <code>test</code></em>. You can limit the execution of build steps at runtime using the<code>when</code>block. As an example, this block executes only on pull requests:</p>
<pre><code class="yaml">pr-builder:
  image: docker:18.03
  environment:
    - DOCKER_HOST=tcp://172.17.0.1:2375
  commands:
    - docker build -t &lt;image_name&gt; .
  when:
    event: pull_request
</code></pre>

<p>Drone will only execute that step when a new pull request is raised (and when pushes are made to the branch while a pull request is open).</p>
<p><a href="http://0-8-0.docs.drone.io/step-conditions/">Read more about Drone conditions</a>.</p>
<h5>Deploying to ACP</h5>
<blockquote>
<p>Please note that this section assumes that you already have kube files to work with (specifically, deployment, service and ingress files).
Examples of these files can be found in the <a href="https://github.com/UKHomeOffice/kube-signed-commit-check">kube-signed-commit-check</a> project.</p>
</blockquote>
<p>Add a deployment script with the following:</p>
<pre><code class="bash">#!/bin/bash
export KUBE_NAMESPACE=&lt;dev-induction&gt;
export KUBE_SERVER=${KUBE_SERVER}
export KUBE_TOKEN=${KUBE_TOKEN}

kd  -f deployment.yaml \
    -f service.yaml \
    -f ingress.yaml
</code></pre>

<blockquote>
<p>Please note that this is only an example script and it will need to be changed to fit your particular application's needs.</p>
</blockquote>
<p>If you deployed this now you would likely receive an error similar to this:</p>
<pre><code class="bash">error: You must be logged in to the server (the server has asked for the client to provide credentials)
</code></pre>

<p>This error appears because <a href="https://github.com/UKHomeOffice/kd">kd</a> needs 3 environment variables to be set before deploying:</p>
<ul>
<li>
<p><code>KUBE_NAMESPACE</code> - The kubernetes namespace you wish to deploy to. <strong>You need to provide the kubernetes namespace as part of the deployment job</strong>.</p>
</li>
<li>
<p><code>KUBE_TOKEN</code> - This is the token used to authenticate against the kubernetes cluster. <strong>If you do not already have a kube token, <a href="kubernetes-user-token.html">here are docs explaining how to get one</a></strong>.</p>
</li>
<li>
<p><code>KUBE_SERVER</code> - This is the address of the kubernetes cluster that you want to deploy to.</p>
</li>
</ul>
<p>You will need to add <code>KUBE_TOKEN</code> and <code>KUBE_SERVER</code> as drone secrets. Information about how to add Drone secrets can be found in the <a href="#publishing-to-quay">publishing to Quay section</a>.</p>
<p>You can verify that the secrets for your repo are present with:</p>
<pre><code class="bash">$ drone secret ls --repository ukhomeoffice/&lt;your-repo&gt;
</code></pre>

<p>Once the secrets have been added, add a new step to your drone pipeline that will execute the deployment script:</p>
<pre><code class="yaml">deploy_to_uat:
  image: quay.io/ukhomeofficedigital/kd:v0.11.0
  secrets:
    - kube_server
    - kube_token
  commands:
    - ./deploy.sh
  when:
    environment: uat
    event: deployment
</code></pre>

<h4 id="using-another-repo">Using Another Repo<a class="headerlink" href="#using-another-repo" title="Permanent link">#</a></h4>
<p>It is possible to access files or deployment scripts from another repo, there are two ways of doing this.</p>
<p>The recommended method is to clone another repo in the current repo (since this only requires maintaining one .drone.yml) using the following step:</p>
<pre><code class="yaml">predeploy_to_uat:
  image: plugins/git
  commands:
    - git clone https://${GITHUB_TOKEN}:x-oauth-basic@github.com/UKHomeOffice/&lt;your_repo&gt;.git
  when:
    environment: uat
    event: deployment
</code></pre>

<p>Your repository is saved in the workspace, which in turn is shared among all steps in the pipeline.</p>
<p>However, if you decide that you want to trigger a completely different pipeline on a separate repository, you can leverage the <a href="https://github.com/UKHomeOffice/drone-trigger">drone-trigger</a> plugin. If you have a secondary repository, you can setup Drone on that repository like so:</p>
<pre><code class="yaml">pipeline:
  deploy_to_uat:
    image: busybox
    commands:
      - echo ${SHA}
    when:
      event: deployment
      environment: uat
</code></pre>

<p>Once you are ready, you can push the changes to the remote repository. In your main repository you can add the following step:</p>
<pre><code class="yaml">trigger_deploy:
  image: quay.io/ukhomeofficedigital/drone-trigger:latest
  drone_server: https://drone.acp.homeoffice.gov.uk
  repo: UKHomeOffice/&lt;deployment_repo&gt;
  branch: &lt;master&gt;
  deploy_to: &lt;uat&gt;
  params: SHA=${DRONE_COMMIT_SHA}
  when:
    event: deployment
    environment: uat
</code></pre>

<p>The settings are very similar to the <code>drone deploy</code> command:</p>
<ul>
<li><code>deploy_to</code> is the <a href="http://0-8-0.docs.drone.io/step-conditions/#environment">environment constraint</a></li>
<li><code>params</code> is a list of comma separated list of arguments. In the command line tool, this is equivalent to <code>-p PARAM1=ONE -p PARAM2=TWO</code></li>
<li><code>repo</code> the repository where the deployment scripts are located</li>
</ul>
<p>The next time you trigger a deployment on the main repository with:</p>
<pre><code class="bash">$ drone deploy UKHomeOffice/&lt;your_repo&gt; 16 uat
</code></pre>

<p>This will trigger a new deployment on the second repository.</p>
<p>Please note that in this scenario you need to inspect 2 builds on 2 separate repositories if you just want to inspect the logs.</p>
<h4 id="versioned-deployments">Versioned deployments<a class="headerlink" href="#versioned-deployments" title="Permanent link">#</a></h4>
<p>When you restart your build, Drone will automatically use the latest version of the code. However always using the latest version of the deployment configuration can cause major issues and isn't recommended. For example when promoting from preprod to prod you want to use the preprod version of the deployment configuration. If you use the latest it could potentially break your production environment, especially as it won't necessarily have been tested.</p>
<p>To counteract this you should use a specific version of your deployment scripts. In fact, you should  <code>git checkout</code> the tag or sha as part of your deployment step.</p>
<p>Here is an example of this:</p>
<pre><code class="yaml">predeploy_to_uat:
  image: plugins/git
  commands:
    - git clone https://${GITHUB_TOKEN}:x-oauth-basic@github.com/UKHomeOffice/&lt;your_repo&gt;.git
  when:
    environment: uat
    event: deployment

deploy_to_uat:
  image: quay.io/ukhomeofficedigital/kd:v0.11.0
  secrets:
    - kube_server
    - kube_token
  commands:
    - apk update &amp;&amp; apk add git
    - git checkout v1.1
    - ./deploy.sh
  when:
    environment: uat
    event: deployment
</code></pre>

<h4 id="migrating-your-pipeline">Migrating your pipeline<a class="headerlink" href="#migrating-your-pipeline" title="Permanent link">#</a></h4>
<h5>Secrets and Signing</h5>
<p>It is no longer necessary to sign your <code>.drone.yml</code> so the <code>.drone.yml.sig</code> can be deleted. Secrets can be defined in the Drone UI or using the CLI. Secrets created using the UI will be available to push, tag and deployment events. To restrict to selected events, or to allow pull request builds to access secrets you must use the CLI.</p>
<p>Pipelines by default do not have access to any Drone secrets that you have added. You must now define which secrets a pipeline is allowed access to in a <code>secrets</code> section in your pipeline. Here is an example of a pipeline that has access to the <code>DOCKER_PASSWORD</code> secret which will be used to push an image to Quay:</p>
<pre><code class="yaml">image_to_quay:
  image: quay.io/ukhomeofficedigital/drone-docker
  secrets:
    - docker_password
  environment:
    - DOCKER_USERNAME=ukhomeofficedigital+&lt;your_robot_username&gt;
  registry: quay.io
  repo: quay.io/ukhomeofficedigital/&lt;your_quay_repo&gt;
  tags:
    - latest
  when:
    branch: master
    event: push
</code></pre>

<blockquote>
<p>Note: Secrets names in the <code>secrets</code> section will have their names uppercased at runtime.</p>
</blockquote>
<p>Organisation secrets are no longer available. This means that if you are using any organisation secrets such as <code>KUBE_TOKEN_DEV</code>, you will need to add a secret in Drone to replace it.</p>
<h4 id="docker-in-docker">Docker-in-Docker<a class="headerlink" href="#docker-in-docker" title="Permanent link">#</a></h4>
<p>The Docker-in-Docker (dind) service is no longer required. Instead, change the Docker host to <code>DOCKER_HOST=tcp://172.17.0.1:2375</code> in the <code>environment</code> section of your pipline, and you will be able to access the shared Docker server on the drone agent. Note that it is only possible to run one Docker build at a time per Drone agent.</p>
<p>Since privileged mode was primarily used for docker in docker, you should remove the <code>privileged: true</code> line from your <code>.drone.yml</code>.</p>
<p>You can also use your freshly built image directly and run commands as part of your pipeline.</p>
<p>Example:</p>
<pre><code class="yaml">pipeline:

  build_image:
    image: docker:18.03
    environment:
      - DOCKER_HOST=tcp://172.17.0.1:2375
    commands:
      - docker build -t hello_world .
    when:
      branch: master
      event: push

  test_image:
    image: hello_world
    commands:
      - ./run-hello-world.sh
    when:
      branch: master
      event: push
</code></pre>

<h4 id="services">Services<a class="headerlink" href="#services" title="Permanent link">#</a></h4>
<p>If you use the <code>services</code> section of your <code>.drone.yml</code> it is possible to reference them using the DNS name of the service.</p>
<p>For example, if using the following section:</p>
<pre><code class="yaml">services:
  database:
    image: mysql
</code></pre>

<p>The mysql server would be available on <code>tcp://database:3306</code></p>
<h4 id="variable-escaping">Variable Escaping<a class="headerlink" href="#variable-escaping" title="Permanent link">#</a></h4>
<p>Any Drone variables (secrets and environment variables) must now be escaped by having two $$ instead of one. Examples:</p>
<pre><code class="yaml">${DOCKER_PASSWORD} --&gt; $${DOCKER_PASSWORD}
${DRONE_TAG} --&gt; $${DRONE_TAG}
${DRONE_COMMIT_SHA} --&gt; $${DRONE_COMMIT_SHA}

</code></pre>

<h2 id="scanning-images-in-drone">Scanning Images in Drone<a class="headerlink" href="#scanning-images-in-drone" title="Permanent link">#</a></h2>
<p>ACP provides Anchore as a scanning solution for images built into the Drone pipeline, allowing users to scan both ephemeral <em>(built within the context of the drone, but not pushed to a repository yet)</em> as well as any public images.</p>
<p>Example pipeline:</p>
<pre><code class="YAML">pipeline:
  build:
    image: docker:17.09.0-ce
    environment:
    - DOCKER_HOST=tcp://172.17.0.1:2375
    commands:
    - docker build -t docker.digital.homeoffice.gov.uk/myimage:$${DRONE_BUILD_NUMBER} .

  scan:
    # The location of the drone plugin
    image: quay.io/ukhomeofficedigital/anchore-submission:latest
    # The optional path of a Dockerfile
    dockerfile: Dockerfile
    # Note the lack of double $ here (due to the way drone injects variables)
    image_name: docker.digital.homeoffice.gov.uk/myimage:${DRONE_BUILD_NUMBER}
    # Indicates the image is locally available
    local_image: true
    # This indicates we are willing tolerate any vulnerabilities which are below medium (valid values: negligible, low, medium, high, critical)
    tolerate: medium
    # An optional whitelist (comma separated list of CVE's)
    whitelist: CVE_SOMENAME_1,CVE_SOMENAME_2
    # An optional whitelist file containing a list of CSV relative to the repo path
    whitelist_file: &lt;PATH&gt;
    # Indicates we should show all vulnerabilities regardless
    show_all_vulnerabilities: false
    # By default the plugin will exit will fail if any vulnerabilities are discovered which are not tolerated,
    # you change this behaviour by setting the below
    fail_on_detection: false
</code></pre>

<h4 id="qas">Q&amp;As<a class="headerlink" href="#qas" title="Permanent link">#</a></h4>
<h5>Q: The build fails with <em>"ERROR:Insufficient privileges to use privileged mode"</em></h5>
<p>A: Remove <code>privileged: true</code> from your <code>.drone.yml</code>. As explained in the <a href="#migrating-your-pipeline">migrating your pipeline section</a>, the primary use of this was for Docker-in-Docker which is not required.</p>
<h5>Q: The build fails with <em>"Cannot connect to the Docker daemon. Is the docker daemon running on this host?"</em></h5>
<p>A: Make sure that your steps contain the environment variable <code>DOCKER_HOST=tcp://172.17.0.1:2375</code> like in this case:</p>
<pre><code class="yaml">my-build:
  image: docker:18.03
  environment:
    - DOCKER_HOST=tcp://172.17.0.1:2375
  commands:
    - docker build -t &lt;image_name&gt; .
  when:
    branch: master
    event: push
</code></pre>

<h5>Q: The build fails when uploading to Quay with the error <em>"Error response from daemon: Get https://quay.io/v2/: unauthorized:..."</em></h5>
<p>A: This is likely because the secret wasn't added correctly or the password is incorrect. Check that the secret has been added to Drone and that you have added the <code>secrets</code> section in your <code>.drone.yaml</code> it to the pipeline that requires it.</p>
<h5>Q: As part of my build process I have two <code>Dockerfiles</code> to produce a Docker image. How can I share files between builds in the same step?</h5>
<p>A: When the pipeline starts, Drone creates a Docker data volume that is passed along all active steps in the pipeline. If the first step creates a <code>test.txt</code> file, the second step can use that file. As an example, this pipeline uses a two step build process:</p>
<pre><code class="yaml">pipeline:

  first-step:
    image: busybox
    commands:
      - echo hello &gt; test.txt
    when:
      branch: master
      event: push

  second-step:
    image: busybox
    commands:
      - cat test.txt
    when:
      branch: master
      event: push
</code></pre>

<h5>Q: Should I use Gitlab with Quay?</h5>
<p>A: Please don't. If your repository is hosted in Gitlab then use Artifactory to publish your images. Images published to Artifactory are kept private.</p>
<p>If you still want to use Quay, you should consider hosting your repository on the open (Github).</p>
<h5>Q: Can I create a token that has permission to create ephemeral/temporary namespaces?</h5>
<p>A: No. This is because there is currently no way to give access to namespaces via regex.</p>
<p>I.e. There is no way to give access to any namespace with the format: <code>my-temp-namespace-*</code> (where * would be build number or something similar).</p>
<p>Alternatively, you can be given a named namespace in the CI cluster. Please create an issue on our <a href="https://support.acp.homeoffice.gov.uk/servicedesk">Support Portal</a> if you require this.</p>
<h2 id="aws-ecr-for-private-docker-images">AWS ECR for Private Docker Images<a class="headerlink" href="#aws-ecr-for-private-docker-images" title="Permanent link">#</a></h2>
<p>AWS ECR (Elastic Container Registry) is now available as a self-service feature via the Platform Hub. Each project has the capability to create their own Docker Repositories and define individual access to each via the use of IAM Credentials.</p>
<h4 id="creating-a-docker-repository">Creating a Docker Repository<a class="headerlink" href="#creating-a-docker-repository" title="Permanent link">#</a></h4>
<p>Anybody that is part of a Project within the Platform Hub will have the ability to create a new Docker Repository.</p>
<ol>
<li>Login to the Platform Hub via https://hub.acp.homeoffice.gov.uk</li>
<li>Navigate to the Projects list: https://hub.acp.homeoffice.gov.uk/projects/list</li>
<li>Select your Project from the list to go to the detail page (e.g. https://hub.acp.homeoffice.gov.uk/projects/detail/acp)<ul>
<li>Ensure you have a <strong>Service</strong> defined within your Project for the Docker Repository to be associated with (check under the <code>SERVICES</code> tab)</li>
</ul>
</li>
<li>Select the <code>ALL DOCKER REPOS</code> tab</li>
<li>Select the <code>REQUEST NEW DOCKER REPO</code> button</li>
<li>Choose the Service to associate this Repository with and provide the name of the Repository to be created (e.g. <code>hello-world-app</code>)</li>
</ol>
<p>The request to create a new Docker Repository can take a few seconds to complete. You can view the status of a Repository by navigating to the <code>ALL DOCKER REPOS</code> tab and viewing the list. Once the request has completed, your Repository should have the <code>Active</code> label associated with it.</p>
<p>This repository won't automatically refresh, but you can hit the <code>REFRESH</code> button above the Repository list or just manually refresh your browser window for updates.</p>
<h4 id="generating-access-credentials">Generating Access Credentials<a class="headerlink" href="#generating-access-credentials" title="Permanent link">#</a></h4>
<p>Access to ECR Repositories is managed via AWS IAM. These IAM credentials are generated via the Platform Hub and access can be managed per user, per Docker Repository.</p>
<ol>
<li>Navigate to the <code>ALL DOCKER REPOS</code> tab for your Project within the Platform Hub</li>
<li>For the Repository you have created, select the <code>MANAGE ACCESS</code> button</li>
<li>At this stage, you can:<ul>
<li>Create a Robot Account(s), which can be used in deployment pipelines in Drone CI for publishing new images to AWS ECR</li>
<li>Select which Project Members have the ability to pull images, and additionally push updates using their own IAM credentials (separate to the Robot Account(s) and CI builds)</li>
</ul>
</li>
<li>For this example, select your own User and press <code>Save</code>.<ul>
<li><strong>Note:</strong> Generally users should never be granted write access, as any write actions should be performed via CI (using the Robot Accounts).</li>
</ul>
</li>
<li>Press the <code>REFRESH</code> button at the top of the page and check the User Access has a status of <code>active</code></li>
</ol>
<p>Robot Accounts are visible under the Docker Repository, and once they reveal an <code>active</code> status the IAM Credentials are displayed alongside it.</p>
<h4 id="accessing-a-docker-repository">Accessing a Docker Repository<a class="headerlink" href="#accessing-a-docker-repository" title="Permanent link">#</a></h4>
<p>Accessing the AWS Container Registry to Pull &amp; Push images is currently a two-step process:
1. Use IAM Credentials to generate a temporary authorisation token
1. Use the temporary authorisation token to authenticate your docker client with ECR</p>
<blockquote>
<p><strong>Note:</strong> The authorisation token generated for docker login is only valid for 12 hours, and so the process above will need to be repeated.</p>
</blockquote>
<h4 id="pre-requisites">Pre-Requisites<a class="headerlink" href="#pre-requisites" title="Permanent link">#</a></h4>
<p>To follow the below steps you must have:
* AWS CLI (version 1.11.91 or above, check with <code>aws --version</code>)
  * Install Guides: <a href="https://docs.aws.amazon.com/cli/latest/userguide/install-linux.html">Linux</a>, <a href="https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html">OSX</a>, <a href="https://docs.aws.amazon.com/cli/latest/userguide/install-windows.html">Windows</a>
* Docker (version 17.06 or above, check with <code>docker --version</code>)</p>
<h4 id="step-1-retrieve-an-authorisation-token">Step 1: Retrieve an authorisation token<a class="headerlink" href="#step-1-retrieve-an-authorisation-token" title="Permanent link">#</a></h4>
<ol>
<li>Navigate to the <code>Connected Identities</code> page: https://hub.acp.homeoffice.gov.uk/identities</li>
<li>Under <code>Amazon ECR</code> you will have access to your own personal IAM Credentials. These credentials will work across multiple projects whose Repositories you have been granted access to.</li>
</ol>
<p>With the AWS IAM Credentials retrieved from the <code>Connected Identities</code> page, setup a local IAM Profile via the Terminal:</p>
<pre><code class="bash">$ aws configure --profile acp-ecr

AWS Access Key ID [None]: XXXXXXXXXXXXXXXXXXXX
AWS Secret Access Key [None]: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Default region name [None]: eu-west-2
Default output format [None]: json

$ export AWS_PROFILE=acp-ecr
</code></pre>

<p>Now, using the aws-cli you can request an authorisation token to perform a docker login:</p>
<pre><code class="bash">$ aws ecr get-login --no-include-email

docker login -u AWS -p &lt;long-auth-token&gt; https://340268328991.dkr.ecr.eu-west-2.amazonaws.com
</code></pre>

<h4 id="step-2-login-with-authorisation-token">Step 2: Login with Authorisation Token<a class="headerlink" href="#step-2-login-with-authorisation-token" title="Permanent link">#</a></h4>
<p>Following a successful <code>ecr get-login</code>, a full docker login command should be returned. Copy and paste the command exactly, to login to the ECR endpoint:</p>
<pre><code class="bash">$ docker login -u AWS -p &lt;long-auth-token&gt; https://340268328991.dkr.ecr.eu-west-2.amazonaws.com

WARNING! Using --password via the CLI is insecure. Use --password-stdin.
Login Succeeded
</code></pre>

<blockquote>
<p><strong>Note:</strong> 
If you get an error from Step 1 such as <code>Unknown options: --no-include-email</code>, your aws-cli client needs updating. You can omit <code>--no-include-email</code> rather than updating your aws-cli client, but the resulting docker login command will include a deprecated <code>-e none</code> flag (needs to be removed prior to running the command).</p>
</blockquote>
<p>Steps 1 and 2 will also not work if you are using AWS CLI (version 2.*). Instead use</p>
<pre><code class="bash">$ aws_account_id=&quot;340268328991&quot;
$ aws_region=&quot;eu-west-2&quot;
$ ecr_url=&quot;${aws_account_id}.dkr.ecr.${aws_region}.amazonaws.com&quot;

$ aws --region &quot;${aws_region}&quot; ecr get-login-password \
    | docker login \
        --password-stdin \
        --username AWS \
        &quot;${aws_account_id}.dkr.ecr.${aws_region}.amazonaws.com&quot;

Login Succeeded
</code></pre>

<h4 id="pulling-pushing-images">Pulling &amp; Pushing Images<a class="headerlink" href="#pulling-pushing-images" title="Permanent link">#</a></h4>
<p>Within the ACP Kubernetes Clusters, you do not need to provide an <code>imagePullSecret</code> as was previously required for images in Artifactory. The ACP Clusters will authenticate behind-the-scenes and be able to successfully pull images from any Docker Repositories you create via the Platform Hub.</p>
<p>The Docker Repositories section of the Platform Hub will provide a URL such as follows for the Repository you have created: <code>340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app</code></p>
<p>Now that you have locally authenticated with AWS ECR, you can pull and push (if write access was granted) images as normal:</p>
<pre><code class="bash">$ docker build . -t 340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app:v0.0.1

Sending build context to Docker daemon  32.78MB
...
Successfully built 882e2cadb649
Successfully tagged 340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app:v0.0.1

$ docker push 340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app:v0.0.1

The push refers to repository [340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app]
afbe4b47c182: Pushed
78147c906fce: Pushed
86177d14466d: Pushed
f55514f6bd18: Pushed
ce74984572d7: Pushed
67d7e5db87ee: Pushed
12d012372115: Pushed
b0bb54920d03: Pushed
835c2760f26b: Pushed
e9bcacee1741: Pushed
cd7100a72410: Pushed
v0.0.1: digest: sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f size: 2628

$ docker pull 340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app:v0.0.1@sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f

sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f: Pulling from acp/hello-world-app
Digest: sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f
Status: Image is up to date for 340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app@sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f
</code></pre>

<h4 id="listing-images-housekeeping">Listing Images &amp; Housekeeping<a class="headerlink" href="#listing-images-housekeeping" title="Permanent link">#</a></h4>
<p>Using the AWS CLI you can list all images that have been pushed to a given repository which you have access to.</p>
<p>For example:</p>
<pre><code class="sh">$ aws ecr list-images --repository-name acp/hello-world-app
{
    &quot;imageIds&quot;: [
        {
            &quot;imageDigest&quot;: &quot;sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f&quot;,
            &quot;imageTag&quot;: &quot;v0.0.1&quot;
        },
        {
            &quot;imageDigest&quot;: &quot;sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f&quot;,
            &quot;imageTag&quot;: &quot;latest&quot;
        }
    ]
}
</code></pre>

<p>To delete old images, you must have write access enabled or perform the action via a Robot Account. Images can be deleted based on a provided tag or digest. When providing a digest, all image tags with the same digest are deleted together.</p>
<pre><code class="sh">$ aws ecr batch-delete-image --repository-name acp/hello-world-app --image-ids imageTag=v0.0.1
{
    &quot;imageIds&quot;: [
        {
            &quot;imageDigest&quot;: &quot;sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f&quot;,
            &quot;imageTag&quot;: &quot;v0.0.1&quot;
        }
    ],
    &quot;failures&quot;: []
}

$ aws ecr batch-delete-image --repository-name acp/hello-world-app --image-ids imageDigest=sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f
{
    &quot;imageIds&quot;: [
        {
            &quot;imageDigest&quot;: &quot;sha256:0309d2655ecef6b4181ee93edfb91f386fc2ebc7849cc88f6e7a18b0d349c35f&quot;,
            &quot;imageTag&quot;: &quot;latest&quot;
        }
    ],
    &quot;failures&quot;: []
}
</code></pre>

<h4 id="managing-image-deployments-via-drone-ci">Managing Image Deployments via Drone CI<a class="headerlink" href="#managing-image-deployments-via-drone-ci" title="Permanent link">#</a></h4>
<p>The Docker Authorisation Token generated via the aws-cli command is only valid for 12 hours, and so this can't be used as a Drone Secret for Docker Image builds. Instead, you would need to store the IAM Credentials for a Robot Account as Drone Secrets and perform the <code>aws ecr get-login</code> + <code>docker login ..</code> step on each build.</p>
<p>To simplify this process you can use a custom Drone ECR plugin, which:
- Builds a docker image in the root repository directory, with custom build arguments passed in (optional)
- Authenticates to ECR using your AWS IAM credentials (stored as Drone Secrets)
- Pushes the image to ECR with the given tags in the list (latest and commit sha)</p>
<p><strong>Example Pipeline:</strong></p>
<pre><code class="yml">pipeline:
  build_push_to_ecr:
    image: quay.io/ukhomeofficedigital/ecr:latest
    secrets:
    - AWS_ACCESS_KEY_ID
    - AWS_SECRET_ACCESS_KEY
    repo: 340268328991.dkr.ecr.eu-west-2.amazonaws.com/acp/hello-world-app
    build_args:
    - APP_BUILD=${DRONE_COMMIT_SHA}
    tags:
    - latest
    - ${DRONE_COMMIT_SHA}
</code></pre>

<blockquote>
<p>The <strong><a href="https://github.com/UKHomeOffice/docker-ecr">UKHomeOffice ECR image</a></strong> above is based off the official <a href="https://hub.docker.com/r/plugins/ecr">Docker ECR Plugin</a>, with amendments to run in ACP Drone CI.</p>
</blockquote>
<h2 id="using-ingress">Using Ingress<a class="headerlink" href="#using-ingress" title="Permanent link">#</a></h2>
<p>An <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a> is a type of Kubernetes resource that allows you to expose your services outside the cluster. It gets deployed and managed exactly like other Kube resources.</p>
<p>Our ingress setup offers two different ingresses based on how restrictively you want to expose your services:
- internal - only people within the VPN can access services
- external - anyone with internet access can access services</p>
<p>The annotation <code>kubernetes.io/ingress.class: "nginx-internal"</code> is used to specify whether the ingress is internal. (<code>kubernetes.io/ingress.class: "nginx-external"</code> is used for an external ingress.)</p>
<p>In the following example the terms "myapp" and "myproject" have been used, these will need to be changed to the relevant names for your project. Where internal is used, this can be changed for an external ingress - everything else stays the same.</p>
<pre><code class="yaml">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    # used to select which ingress this resource should be configured on
    kubernetes.io/ingress.class: &quot;nginx-internal&quot;
    # Indicate the ingress SHOULD speak TLS between itself and pods (best-practice)
    ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;
  name: myapp-server-internal
spec:
  rules:
  - host: &quot;myapp.myproject.homeoffice.gov.uk&quot;
    http:
      paths:
      - backend:
          serviceName: myapp
          servicePort: 8000
        path: /
  tls:
  - hosts:
    - &quot;myapp.myproject.homeoffice.gov.uk&quot;
    # the name of the kubernetes secret in your namespace with tls.crt and tls.key
    secretName: myapp-github-internal-tls
</code></pre>

<p>Please view the official documentation for a full list of available <a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/">ingress-nginx annotations</a>.</p>
<blockquote>
<p><strong>Note:</strong> Where the prefix for the annotation in the docs references <code>nginx.ingress.kubernetes.io/</code>, this should be changed to <code>ingress.kubernetes.io/</code> when running within ACP (as per the above example).</p>
</blockquote>
<h1 id="cert-manager"><strong>Cert Manager</strong><a class="headerlink" href="#cert-manager" title="Permanent link">#</a></h1>
<h2 id="very-important-upgrade-information">VERY IMPORTANT upgrade information<a class="headerlink" href="#very-important-upgrade-information" title="Permanent link">#</a></h2>
<p><code>cert-manager</code> is being upgraded from v0.8 to v0.13.1. If you have cert-manager resources deployed in your namespaces, you MUST follow the <a href="cert-manager-upgrade-from-v0.8.html">instructions to upgrade from v0.8</a> to upgrade annotations and labels in order for them to be managed by the new version of cert-manager.</p>
<p>To find out if you are using v0.8 cert-manager resources in your namespace, you can run:</p>
<pre><code>kubectl get certificates.certmanager.k8s.io
</code></pre>

<p>Also LetsEncrypt will no longer be supporting PSG's kube-cert-manager from June 2020. So if you are using PSG kube-cert-manager to obtain certificates for your ingresses, you also need to migrate to JetStack's cert-manager v0.13.1 and follow the <a href="cert-manager-upgrade-from-psg.html">instructions to upgrade from PGS's kube-cert-manager</a></p>
<p>To find out if you are using PSG kube-cert-manager to manage your ingresses certificates, you can run:</p>
<pre><code>kubectl get ingresses -o yaml | grep stable.k8s.psg.io
</code></pre>

<p>Please also be aware that admission policies have been updated and will reject <code>Ingress</code> resources with annotations or labels supported by more than one certificate manager. There are currently ingresses with both cert-manager v0.8 and PSG annotations or labels and those will now fail applying.</p>
<h2 id="background">Background<a class="headerlink" href="#background" title="Permanent link">#</a></h2>
<p>The ACP platform presently has two certificate management services.</p>
<p>The first service was PSG's <a href="https://github.com/PalmStoneGames/kube-cert-manager">kube-cert-manager</a>. However with the forever changing landscape the project gradually became deprecated and now recommends replacement with JetStack's <a href="https://github.com/jetstack/cert-manager">cert-manager</a>.</p>
<p>Therefore, projects still using kube-cert-manager should modify their services to start using cert-manager instead. Note that ACP will continue to support kube-cert-manager and the internal cfssl service while they are still in use, but we do recommend shifting over to cert-manager as soon as possible as aside from security fixes there will not be any more updates to these services.</p>
<p>Without wishing to duplicate documentation which can be found in the <a href="https://github.com/jetstack/cert-manager/blob/master/README.md">readme</a> and or official <a href="https://cert-manager.io/docs/">documentation</a>, cert-manager can effectively replace two services:</p>
<ul>
<li>kube-cert-manager: used to acquire certificates from LetsEncrypt.</li>
<li>cfssl: an internal Cloudflare service used to generate internal certificate <em>(usually to encrypt between ingress and pod)</em>.</li>
</ul>
<p><strong>IMPORTANT NOTE:</strong></p>
<p><code>cert-manager</code> is being upgraded from v0.8 to v0.13.1. In order to allow development teams to upgrade their <code>cert-manager</code> resources according to their own schedule, both v0.8 and v.13.1 resources will be available concurrently for a period of time.</p>
<p>While the older version of <code>cert-manager</code> (v0.8) is still available on the ACP platform, resources managed by the newer version of cert-manager (v0.13.1+) can only be accessed from the API server by suffixing the resource kind with <code>.cert-manager.io</code>.</p>
<p>For example:</p>
<pre><code># to access v0.13.1 cert-manager resources
kubectl -n project get certificate.cert-manager.io
kubectl -n project get orders.acme.cert-manager.io
kubectl -n project get challenge.acme.cert-manager.io
</code></pre>

<pre><code># to access v0.8 cert-manager resources
kubectl -n project get certificate
kubectl -n project get orders
kubectl -n project get challenge
# or
kubectl -n project get certificate.certmanager.k8s.io
kubectl -n project get orders.certmanager.k8s.io
kubectl -n project get challenge.certmanager.k8s.io
</code></pre>

<h2 id="how-tos_1"><strong>How-tos</strong><a class="headerlink" href="#how-tos_1" title="Permanent link">#</a></h2>
<h3 id="as-a-developer-i-already-have-a-certificate-from-the-legacy-kube-cert-manager-how-do-i-migrate"><strong>As a developer I already have a certificate from the legacy kube-cert-manager, how do I migrate?</strong><a class="headerlink" href="#as-a-developer-i-already-have-a-certificate-from-the-legacy-kube-cert-manager-how-do-i-migrate" title="Permanent link">#</a></h3>
<p>Migrating from the former <a href="https://github.com/PalmStoneGames/kube-cert-manager">kube-cert-manager</a> over to <a href="https://github.com/jetstack/cert-manager">cert-manager</a> means creating the certificate request as below and removing the annotations from the ingress. However, the safe way would be to;</p>
<ul>
<li>Create a new Certificate resource and point to a <strong>new</strong> secret name <em>(thus keeping the old one incase)</em>.</li>
<li>Push out the change and wait for the certificate to be fulfilled.</li>
<li>Once you have the certificate you can update your ingress to use the new secret,<strong>remove</strong> the annotations and use the Certificate resource thereafter.</li>
</ul>
<h3 id="as-a-developer-i-want-to-retrieve-an-internal-certificate"><strong>As a developer I want to retrieve an internal certificate</strong><a class="headerlink" href="#as-a-developer-i-want-to-retrieve-an-internal-certificate" title="Permanent link">#</a></h3>
<p>As stated above the cert-manager can also handle internal certificates i.e. those signed by the internal ACP Certificate Authority <em>(this is self signed btw)</em>. At the moment you might be using <a href="https://github.com/UKHomeOffice/cfssl-sidekick">cfssl-sidekick</a> to perform this, but this can be completely replaced.</p>
<p>If you want to create a certificate for a service, assuming the service is called <code>myservice</code> in namespace <code>mynamespace</code>, the Certificate definition would look like:</p>
<pre><code class="YAML">apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: tls
spec:
  secretName: tls
  issuerRef:
    name: platform-ca
    kind: ClusterIssuer
  dnsNames:
  - myservice
  - myservice.mynamespace
  - myservice.mynamespace.svc
  - myservice.mynamespace.svc.cluster.local
  - localhost
  ipAddresses:
  - 127.0.0.1
</code></pre>

<p>Ingress resources are checked by admission policies to ensure the platform-ca cluster issuer only issues certificates for DNS names that are hosted inside the namespace.</p>
<p>So if you want to create a certificate for a replica in a statefulset, assuming your statufelset is called <code>mysts</code>, the Certificate definition would look like:</p>
<pre><code class="YAML">apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: tls
spec:
  secretName: tls
  issuerRef:
    name: platform-ca
    kind: ClusterIssuer
  dnsNames:
  - mysts-0.myservice.mynamespace
  - mysts-0.myservice.mynamespace.svc
  - mysts-0.myservice.mynamespace.svc.cluster.local
  - localhost
  ipAddresses:
  - 127.0.0.1
</code></pre>

<p>Note that <code>mysts-0.myservice</code> is intentionally missing from the list in <code>dnsNames</code> because those names need to be either a hostname (for the service) or a name ending with <code>mynamespace</code>, <code>mynamespace.svc</code> or <code>mynamespace.svc.cluster.local</code>.</p>
<p>This would create a kubernetes secret named <code>tls</code> in your namespace with the signed certificate. An interesting thing to note here is that although this is using the ClusterIssuer platform-ca created by the ACP team, there is nothing stopping a project from creating a local Issuer for their own project. So for example.</p>
<pre><code class="YAML">---
apiVersion: cert-manager.io/v1alpha2
kind: Issuer
metadata:
  name: project-ca
spec:
  ca:
    secretName: project-ca
---
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: tls
spec:
  secretName: tls
  issuerRef:
    name: project-ca
    # @Note: we have change from ClusterIssuer to a local Issuer
    kind: Issuer
  commonName: site.svc.project.cluster.local
  dnsNames:
  - localhost
  ipAddresses:
  - 127.0.0.1
</code></pre>

<p>Finally, if you want to use your certificate for client auth (as well as server auth in the following example), you need to add a <code>keyUsages</code> section to your Certificate resource:</p>
<pre><code class="YAML">apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: tls
spec:
  secretName: tls
  issuerRef:
    name: platform-ca
    kind: ClusterIssuer
  keyUsages:
  - server auth
  - client auth
  dnsNames:
  - myservice
  - myservice.mynamespace
  - myservice.mynamespace.svc
  - myservice.mynamespace.svc.cluster.local
  - localhost
  ipAddresses:
  - 127.0.0.1
</code></pre>

<h3 id="as-a-developer-i-want-to-retrieve-a-certificate-for-my-external-service"><strong>As a developer I want to retrieve a certificate for my external service</strong><a class="headerlink" href="#as-a-developer-i-want-to-retrieve-a-certificate-for-my-external-service" title="Permanent link">#</a></h3>
<p>Let's assume we have an externally facing site which we wish to expose via ingress and we want a valid LetsEncrypt certificate.</p>
<p>Getting a certificate associated with the external ingress only requires to annotate the ingress with <code>cert-manager.io/enabled</code>, which is a toggle to ask cert-manager to handle this ingress resource.</p>
<p>Optionally, the acme solver to be used by the cluster issuer can be specified with label <code>cert-manager.io/solver: http01</code>. However, this is not required as the <code>http01</code> acme solver is the default one.</p>
<p>Please note that <code>cert-manager.io/enabled</code> is an annotation but <code>cert-manager.io/solver</code> is a label.</p>
<p>When the site is externally facing i.e. the ingress class on the ingress is <code>kubernetes.io/ingress.class: nginx-external</code> you should always default to using a http01 challenge. However, if you know that the domain whitelisted in your namespace is hosted in AWS by Route53, you can instead specify a label of <code>cert-manager.io/solver: route53</code></p>
<pre><code class="YAML">apiVersion: networking.k8s.io/v1beta1
  kind: Ingress
  metadata:
    annotations:
      # @NOTE: this will enable cert-manager to handle this resource
      cert-manager.io/enabled: &quot;true&quot;
      ingress.kubernetes.io/affinity: cookie
      ingress.kubernetes.io/force-ssl-redirect: &quot;true&quot;
      ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;
      ingress.kubernetes.io/session-cookie-name: ingress
      ingress.kubernetes.io/ssl-redirect: &quot;true&quot;
      kubernetes.io/ingress.class: nginx-external
    name: example
  # @NOTE: the following label can be specified to ask letsencrypt to use the http01 acme challenge
  # @NOTE: but it is not required as http01 is the default solver
  labels:
    cert-manager.io/solver: http01

  spec:
    rules:
    - host: www.example.com
      http:
        paths:
        - backend:
            serviceName: service_name
            servicePort: 10443
          path: /
    tls:
    - hosts:
      - www.example.com
      # @NOTE: this is the name of the kubernetes secret that cert-manager will manage in your namespace
      secretName: example-tls
</code></pre>

<p>A few things to note here:</p>
<ul>
<li>behind the scenes, cert-manager works with the <code>Certificate</code> custom resource.</li>
<li>when using ingress annotations and labels, cert-manager uses another internal controller to pick up the ingress resources and create a <code>Certificate</code> resource on your behalf. Of course, you can instead define this directly yourself but you will also have to define annotations on the ingress resource to specify which secret should be used for TLS termination. This is the recommended and safest approach when migrating from <code>kube-cert-manager</code> to <code>cert-manager</code>.</li>
</ul>
<pre><code class="YAML">apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: example
spec:
  commonName: www.example.com
  dnsNames:
  - www.example.com
  issuerRef:
    kind: ClusterIssuer
    # @Note: we support letsencrypt-prod and letsencrypt-staging (use the latter to test your cert-manager related manifests)
    name: letsencrypt-prod
  secretName: example-tls
</code></pre>

<p>You can review, get, list and describe the Certificate like any other kubernetes resource within your namespace.</p>
<pre><code class="shell">$ kubectl -n project get certificate
NAME        AGE
example-tls    1d

# you can also review the certificaterequests, orders and challenges via
$ kubectl -n project get orders
$ kubectl -n project get challenge
</code></pre>

<p><strong>Network Policies</strong></p>
<p>Please note that as part of the implementation of cert-manager v0.13.1, a <code>GlobalNetworkPolicy</code> object managing ingress traffic for <code>http01</code> challenges has been deployed.</p>
<p>This means that you no longer need to have a <code>NetworkPolicy</code> in your namespaces allowing ingress traffic from port 8089 to the ephemeral pods that cert-manager creates to handle the <code>http01</code> challenge.</p>
<h3 id="as-a-developer-i-want-to-retrieve-a-certificate-for-a-service-behind-the-vpn-or-simply-wish-to-use-the-dns-validation"><strong>As a developer I want to retrieve a certificate for a service behind the vpn, or simply wish to use the DNS validation</strong><a class="headerlink" href="#as-a-developer-i-want-to-retrieve-a-certificate-for-a-service-behind-the-vpn-or-simply-wish-to-use-the-dns-validation" title="Permanent link">#</a></h3>
<p>When a site is internal / behind the vpn, in order to handle the challenge you need to switch to using a DNS challenge.</p>
<p>This is done by adding the following to your ingress resource:</p>
<ul>
<li>annotation <code>cert-manager.io/enabled: "true"</code></li>
<li>label <code>cert-manager.io/solver: route53</code></li>
</ul>
<p><strong>Very Important</strong>: in order to successfully switch to a DNS challenge, please ensure you have contacted the ACP team before attempting this for the first time on your sub-domain as the correct permissions need to exist to permit cert-manager to add records to the domain.</p>
<pre><code class="YAML">apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: example-tls
  labels:
    # @Note: this label tells the cluster issuer to use the DNS01 Route53 solver instead of the default HTTP01 solver
    cert-manager.io/solver: route53
spec:
  secretName: example-tls
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: mysite.example.com
  dnsNames:
  - example.com
  acme:
    config:
    - dns01:
        provider: route53
      domains:
      - mysite.example.com
      - example.com
</code></pre>

<p>Or via ingress you would use</p>
<pre><code class="YAML">apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: example
  annotations:
    # @Note: get cert-manager to manage this ingress
    cert-manager.io/enabled: &quot;true&quot;
    kubernetes.io/ingress.class: nginx-internal
  labels:
    # @Note: this label tells the cluster issuer to use the DNS01 Route53 solver instead of the default HTTP01 solver
    cert-manager.io/solver: route53
spec:
  rules:
  - host: mysite.example.com
    http:
      paths:
      - backend:
          serviceName: service_name
          servicePort: 443
        path: /
  tls:
  - hosts:
    - mysite.example.com
    - example.com
    secretName: example-tls
</code></pre>

<h3 id="as-a-developer-i-want-to-use-letsencrypt-staging-while-configuring-my-cert-manager-resources"><strong>As a developer I want to use LetsEncrypt staging while configuring my cert-manager resources</strong><a class="headerlink" href="#as-a-developer-i-want-to-use-letsencrypt-staging-while-configuring-my-cert-manager-resources" title="Permanent link">#</a></h3>
<p>You should use the staging version of LetsEncrypt in order to not be impacted by rate limits of the production version while setting up and testing the cert-manager annotations and labels you specify on your resources.</p>
<p>By default, the production version of the LetsEncrypt ACME servers is used.</p>
<p>To use the staging version, use the <code>cert-manager.io/cluster-issuer</code> annotation:</p>
<pre><code class="YAML">apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: example
  annotations:
    cert-manager.io/enabled: &quot;true&quot;
    kubernetes.io/ingress.class: nginx-internal
    # @Note: we are specifying which cluster issuer to use
    cert-manager.io/cluster-issuer: letsencrypt-staging
labels:
    cert-manager.io/solver: route53
spec:
  rules:
  - host: mysite.example.com
    http:
      paths:
      - backend:
          serviceName: service_name
          servicePort: 443
        path: /
  tls:
  - hosts:
    - mysite.example.com
    - example.com
    secretName: example-tls
</code></pre>

<p>Not specifying this annotation is equivalent to specifying <code>cert-manager.io/cluster-issuer: letsencrypt-prod</code>.</p>
<p>Please note that the certificates issued by the staging version of LetsEncrypt are not signed and should not be used in production.</p>
<h3 id="as-a-developer-i-want-to-get-a-certificate-for-a-server-with-a-dns-name-longer-than-63-characters"><strong>As a developer I want to get a certificate for a server with a DNS name longer than 63 characters</strong><a class="headerlink" href="#as-a-developer-i-want-to-get-a-certificate-for-a-server-with-a-dns-name-longer-than-63-characters" title="Permanent link">#</a></h3>
<p>A certificate's <code>commonName</code> is used to create a Certificate Signing Request and populate a field that is limited to 63 characters.</p>
<p>In order to get a certificate for a server with a DNS name longer than 63 characters, you need to specify a common name of less than 63 characters and add the desired DNS name as an additional entry to <code>dnsNames</code>.</p>
<p>For example, with an <code>Ingress</code>:</p>
<pre><code class="YAML">apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: example
  annotations:
    cert-manager.io/enabled: &quot;true&quot;
    kubernetes.io/ingress.class: nginx-internal
  labels:
    cert-manager.io/solver: route53
spec:
  rules:
  - host: my-rather-long-winded-service-name.my-namespace.subdomain.example.com
    http:
      paths:
      - backend:
          serviceName: service_name
          servicePort: 443
        path: /
  tls:
  - hosts:
    - svc-1.my-namespace.subdomain.example.com
    - my-rather-long-winded-service-name.my-namespace.subdomain.example.com
    secretName: example-tls
</code></pre>

<p>Or with a <code>Certificate</code>:</p>
<pre><code class="YAML">apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: example
spec:
  secretName: example-tls
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: svc-1.my-namespace.subdomain.example.com
  dnsNames:
  - svc-1.my-namespace.subdomain.example.com
  - my-rather-long-winded-service-name.my-namespace.subdomain.example.com
</code></pre>

<h2 id="getting-a-kubernetes-robot-token">Getting a Kubernetes Robot Token<a class="headerlink" href="#getting-a-kubernetes-robot-token" title="Permanent link">#</a></h2>
<h4 id="users">Users<a class="headerlink" href="#users" title="Permanent link">#</a></h4>
<ol>
<li>
<p>Log into the <a href="https://hub.acp.homeoffice.gov.uk">Platform Hub</a>.</p>
</li>
<li>
<p>Go to the <a href="https://hub.acp.homeoffice.gov.uk/projects/list">Projects</a> section and find your project. Click on the <strong>Services</strong> tab and find the service that requires a robot token.</p>
</li>
<li>
<p>Go to the <strong>Kube Robot Tokens</strong> tab. Any robot tokens that have been created for that service will be listed. You can see the full token by clicking on the eye icon next to the token.</p>
</li>
</ol>
<p>If there are no robot tokens for that service, or the required one is not there, you will need to ask your project admin(s) to create a robot token.</p>
<h4 id="project-admins-creating-a-robot-token">Project Admins (Creating a robot token)<a class="headerlink" href="#project-admins-creating-a-robot-token" title="Permanent link">#</a></h4>
<ol>
<li>
<p>Log into the <a href="https://hub.acp.homeoffice.gov.uk">Platform Hub</a>.</p>
</li>
<li>
<p>Go to the <a href="https://hub.acp.homeoffice.gov.uk/projects/list">Projects</a> section and find your project. Click on the <strong>Services</strong> tab and find the service that requires a robot token.</p>
</li>
<li>
<p>Go to the <strong>Kube Robot Tokens</strong> tab and click the <strong>Create a Kubernetes robot token for this service</strong> button.</p>
</li>
<li>
<p>Select the required cluster, RBAC group(s), robot name and description for the robot token and click <strong>Create</strong>.</p>
</li>
</ol>
<blockquote>
<p>An explanation of RBAC groups can be found here: <a href="https://github.com/UKHomeOffice/application-container-platform/blob/master/docs/rbac.md">RBAC Groups</a></p>
</blockquote>
<ol>
<li>Users who are part of the project will be able to view the token in the same place you created it (Project -&gt; Service -&gt; Kube Robot Tokens).</li>
</ol>
<h2 id="getting-a-kubernetes-token">Getting a Kubernetes Token<a class="headerlink" href="#getting-a-kubernetes-token" title="Permanent link">#</a></h2>
<h4 id="users_1">Users<a class="headerlink" href="#users_1" title="Permanent link">#</a></h4>
<ol>
<li>
<p>Log into the <a href="https://hub.acp.homeoffice.gov.uk">Platform Hub</a>.</p>
</li>
<li>
<p>Go to the <a href="https://hub.acp.homeoffice.gov.uk/projects/list">Projects</a> section and find your project. On the <strong>Overview &amp; People</strong> tab, you should see a list of team members and the project admin (who will have the admin tag next to their name).</p>
</li>
<li>
<p>Talk to your project admin and ask them to generate a user token for you.</p>
</li>
<li>
<p>Once your token has been created, you will be able to find it in the <a href="https://hub.acp.homeoffice.gov.uk/identities">Connected Identities</a> section. You will need to expand the <strong>Kubernetes</strong> identity and show your full token by clicking the eye icon next to it.</p>
</li>
</ol>
<h4 id="project-admins-creating-a-user-token">Project Admins (Creating a user token)<a class="headerlink" href="#project-admins-creating-a-user-token" title="Permanent link">#</a></h4>
<ol>
<li>
<p>Log into the <a href="https://hub.acp.homeoffice.gov.uk">Platform Hub</a>.</p>
</li>
<li>
<p>Go to the <a href="https://hub.acp.homeoffice.gov.uk/projects/list">Projects</a> section and find your project. Click on the <strong>Kube User Tokens</strong> tab, click <strong>Select a project team member</strong> and select the requesters name from the list.</p>
</li>
<li>
<p>Click <strong>CREATE A NEW KUBERNETES USER TOKEN FOR THIS USER</strong>.</p>
</li>
<li>
<p>Select the required cluster and RBAC group(s) needed for the token and click <strong>Create</strong>.</p>
</li>
</ol>
<blockquote>
<p>An explanation of RBAC groups can be found here: <a href="https://github.com/UKHomeOffice/application-container-platform/blob/master/docs/rbac.md">RBAC Groups</a></p>
</blockquote>
<ol>
<li>Once the token is created the requester should be able to see it in their <strong>Connected Identities</strong> section for use in their Kube config.</li>
</ol>
<p><strong>Note:</strong> Tokens can take a while to propagate so you may have to wait for up to 10 minutes before using a new token.</p>
<h2 id="network-policies">Network Policies<a class="headerlink" href="#network-policies" title="Permanent link">#</a></h2>
<p>By default a deny-all policy is applied to every namespace in each cluster.</p>
<p>You can however add network policies to your own projects to allow for certain connections and these will be applied on top of the default deny-all policy.</p>
<p>Here is an example network policy for allowing a connection from the ingress-internal namespace:</p>
<pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ingress-network-policy
  namespace: &lt;your-namespace-here&gt;
spec:
  podSelector:
    matchLabels:
      role: artifactory
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-internal
      ports:
        - protocol: TCP
          port: 443
</code></pre>

<p>The port number should be the same as the one that your service is listening on.</p>
<h4 id="controlling-egress-traffic">Controlling Egress Traffic<a class="headerlink" href="#controlling-egress-traffic" title="Permanent link">#</a></h4>
<p>Kubernetes v1.8 with Calico v2.6 adds support to limit egress traffic via the use of Kubernetes Network Policies.</p>
<p>An example of a policy document blocking ALL egress traffic for a given namespace is below:</p>
<pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-egress
  namespace: &lt;your-namespace-here&gt;
spec:
  podSelector:
    matchLabels: {}
  policyTypes:
  - Egress
</code></pre>

<p><strong>NOTE:</strong> The above document will also prevent DNS access for all pods in the namespace. To allow DNS egress traffic via the <code>kube-system</code> namespace, you can apply the following Network Policy document within your namespace (which takes precedence over <code>deny-all-egress</code>):</p>
<pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-dns-access
  namespace: &lt;your-namespace-here&gt;
spec:
  podSelector:
    matchLabels: {}
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
</code></pre>

<p>For more information, please see the following:
- <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Kubernetes documentation on network policies</a>
- <a href="https://docs.projectcalico.org/master/getting-started/kubernetes/tutorials/advanced-policy">Kubernetes advanced network policy examples</a></p>
<h2 id="run-performance-tests-on-a-service-hosted-on-acp">Run Performance Tests on a service hosted on ACP<a class="headerlink" href="#run-performance-tests-on-a-service-hosted-on-acp" title="Permanent link">#</a></h2>
<h4 id="as-a-service-i-should">As a Service, I should:<a class="headerlink" href="#as-a-service-i-should" title="Permanent link">#</a></h4>
<ul>
<li>Always have a baseline set of metrics of my isolated service</li>
<li>Understand what those metrics need to be for each functionality i.e. how long file uploads should take vs a generic GET request</li>
<li>Make sure the baseline does not include any other components i.e. networks, infrastructure etc.</li>
<li>Expose a set of metrics, see <a href="../services.html##metrics-monitoring">Metrics</a></li>
<li>Make performance testing part of my Continuous Integration workflow</li>
<li>Have a history of performance over time</li>
</ul>
<h4 id="assessed-tools-summary">Assessed tools summary:<a class="headerlink" href="#assessed-tools-summary" title="Permanent link">#</a></h4>
<ul>
<li>An example usage of Blazemeter's Taurus in a drone pipeline can be seen in the <a href="https://github.com/UKHomeOffice/taurus-project-x">taurus-project-x repo</a>.</li>
<li><a href="https://github.com/shoreditch-ops/artillery">Artillery</a> (<a href="https://www.npmjs.com/package/artillery">npm</a>) was also tested w/ the <a href="https://github.com/shoreditch-ops/artillery-plugin-statsd">statsd plugin</a>, visualising data in grafana.</li>
<li>SonarQube plugin jmeter-sonar is now deprecated. The latest version of sonarqube does not to have plugin support for jmeter</li>
<li>another option is <a href="https://docs.k6.io/docs">k6</a> - tool is written in go and tests are written in javascript. To visualise the only option is InfluxDB and Grafana.</li>
</ul>
<h2 id="pod-security-policies">Pod Security Policies<a class="headerlink" href="#pod-security-policies" title="Permanent link">#</a></h2>
<p>By default all user deployments will inherit a default PodSecurityPolicy applied accross our Kubernetes clusters, which define a set of conditions that a pod must be configured with in order to run successfully.</p>
<h4 id="runasuser"><code>runAsUser</code><a class="headerlink" href="#runasuser" title="Permanent link">#</a></h4>
<p>This condition requires that the pod specification deploys an image with a non-root user. The user defined in the specification (image spec OR pod spec) must be numeric, so that Kubernetes will be able to verify that it is a non-root user. If this is not done, you may receive any of the following errors in your event log and your pod will be prevented from starting up successfully:
- <code>container's runAsUser breaks non-root policy</code>
- <code>container has runAsNonRoot and image will run as root</code>
- <code>container has runAsNonRoot and image has non-numeric user &lt;username&gt;, cannot verify user is non-root</code></p>
<blockquote>
<p><strong>Note:</strong> You can view all recent events in your namespace by running the following command: <code>kubectl -n my-namespace get events --sort-by=.metadata.creationTimestamp</code>.</p>
</blockquote>
<p>To update your deployment accordingly for the above condition, there are multiple ways to achieve this:</p>
<h4 id="dockerfile">Dockerfile<a class="headerlink" href="#dockerfile" title="Permanent link">#</a></h4>
<p>Within the <code>Dockerfile</code> for the image you are attempting to run, ensure the <code>USER</code> specified references the User ID rather than the username itself. For example:</p>
<pre><code>FROM quay.io/gambol99/keycloak-proxy:v2.1.1
LABEL maintainer=&quot;rohith.jayawardene@digital.homeoffice.gov.uk&quot;

RUN adduser -D -u 1000 keycloak

USER 1000
</code></pre>

<blockquote>
<p><strong>Note:</strong> The following common images have been updated to reference the UID within their respective Dockerfiles. If you use any of these images, updating your deployments to use these versions (or any newer versions) will meet the <code>MustRunAsNonRoot</code> requirement for this particular container:</p>
</blockquote>
<pre><code>quay.io/ukhomeofficedigital/cfssl-sidekick:v0.0.6
quay.io/ukhomeofficedigital/elasticsearch:v1.5.3
quay.io/ukhomeofficedigital/jira:v7.9.1
quay.io/ukhomeofficedigital/keycloak:v3.4.3-2
quay.io/ukhomeofficedigital/kibana:v0.4.4
quay.io/ukhomeofficedigital/go-keycloak-proxy:v2.1.1
quay.io/ukhomeofficedigital/nginx-proxy:v3.2.9
quay.io/ukhomeofficedigital/nginx-proxy-govuk:v3.2.9.0
quay.io/ukhomeofficedigital/redis:v0.1.2
quay.io/ukhomeofficedigital/squidproxy:v0.0.5
</code></pre>

<h4 id="deployment-spec">Deployment Spec<a class="headerlink" href="#deployment-spec" title="Permanent link">#</a></h4>
<p>In the <code>securityContext</code> section of your deployment spec, the <code>runAsUser</code> field can be used to set a UID that the image should be run as.</p>
<p>An example spec would include:</p>
<pre><code class="YAML">    spec:
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
      containers:
      - name: &quot;{{ .IMAGE_NAME }}&quot;
        image: &quot;{{ .IMAGE }}:{{ .VERSION }}&quot;
        ...
</code></pre>

<h2 id="using-artifactory-as-a-private-npm-registry">Using artifactory as a private npm registry<a class="headerlink" href="#using-artifactory-as-a-private-npm-registry" title="Permanent link">#</a></h2>
<p>A step-by-step guide.</p>
<p>This guide makes the following assumptions:</p>
<ul>
<li>you have drone ci set up for your project already</li>
<li>you are using <code>node@8</code> and <code>npm@5</code> or later</li>
<li>you are connected to ACP VPN</li>
</ul>
<h4 id="setting-up-a-local-environment">Setting up a local environment<a class="headerlink" href="#setting-up-a-local-environment" title="Permanent link">#</a></h4>
<h5>Get your username and API key from artifactory</h5>
<p>Visit https://artifactory.digital.homeoffice.gov.uk/artifactory/webapp/#/profile, make a note of your username, and if you don't already have an API key then generate one.</p>
<h5>base64 encode your API key</h5>
<pre><code>echo -n &lt;api key&gt; | base64
</code></pre>

<h5>Set local environment variables</h5>
<p>Copy your encoded password, and set the following environment variables in your bash profile:</p>
<pre><code>export NPM_AUTH_USERNAME=&lt;username&gt;
export NPM_AUTH_TOKEN=&lt;base64 encoded api key&gt;
</code></pre>

<p>You might then need to <code>source</code> your profile to load these environment variables.</p>
<h4 id="setting-up-ci-in-drone">Setting up CI in drone<a class="headerlink" href="#setting-up-ci-in-drone" title="Permanent link">#</a></h4>
<h5>Request a bot token for artifactory</h5>
<p>You can do this through the <a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/30">ACP Support Portal</a>.</p>
<p>One of the ACP team will create a token and send it to you as an encrypted gpg file via email.</p>
<p>Decrypt the token</p>
<pre><code>gpg --decrypt ./path/to/file.gpg
</code></pre>

<h5>Add the token to drone as a secret</h5>
<p>First, base64 encode the token:</p>
<pre><code>echo -n &quot;&lt;token&gt;&quot; | base64
</code></pre>

<p>Then add this token to drone as a secret:</p>
<pre><code>drone secret add UKHomeOffice/&lt;repo&gt; NPM_AUTH_TOKEN &lt;base64-encoded-token&gt; --event pull_request
</code></pre>

<p><strong>Note: You will need to make sure the event types are lowercase. If an event is capitalised, it won't match the standard events inside of drone</strong></p>
<p>Note: you will need to make the secret available to pull request builds to be able to run npm commands in pull request steps</p>
<h5>Expose secret to build steps</h5>
<p>You will need to configure any steps which use npm to be able to access the secret. Do this by adding a <code>secret</code> property to those steps as follows:</p>
<pre><code class="yaml">  my_step:
    image: node:8
    secrets:
      - npm_auth_token
    commands:
      - npm install
      - npm test
</code></pre>

<h5>Expose username to build steps</h5>
<p>In addition, you will need to add the username (as you provided when creating your token) as an environment variable. The easiest way to do this is as a "matrix" variable, which makes the username available to all steps without needing to configure them all individually.</p>
<pre><code class="yaml">matrix:
  NPM_AUTH_USERNAME:
    - &lt;username&gt;
</code></pre>

<h4 id="publishing-modules-to-artifactory">Publishing modules to artifactory<a class="headerlink" href="#publishing-modules-to-artifactory" title="Permanent link">#</a></h4>
<p>It is generally recommended to use a common namespace to publish your modules under. npm allows namespace specific configuration, which makes it easier to ensure that modules are always installed from artifactory, and will not accidentally try to install a public module with the same name.</p>
<h5>Setting publish registry</h5>
<p>Add <code>publishConfig</code> to package.json. This ensures that the module can only ever be published to the private registry, and misconfiguration won't accidentally make it public</p>
<pre><code class="json">&quot;publishConfig&quot;: {
  &quot;registry&quot;: &quot;https://artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/&quot;
}
</code></pre>

<h5>Add auth settings</h5>
<p>In your project's <code>.npmrc</code> file (create one if it does not already exist) add the following lines:</p>
<pre><code>//artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/:username=${NPM_AUTH_USERNAME}
//artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/:_password=${NPM_AUTH_TOKEN}
//artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/:email=test@example.com
</code></pre>

<p>The email address can be anything, it just needs to be set.</p>
<h5>Add publish step to drone</h5>
<p>Add the following step to your <code>.drone.yml</code> file to publish a new version whenever you release a tag.</p>
<pre><code class="yaml">  publish:
    image: node:8
    secrets:
      - npm_auth_token
    commands:
      - npm publish
    when:
      event: tag
</code></pre>

<p>Now, when you push new tags to github then drone should publish them to the artifactory npm registry automatically.</p>
<h4 id="using-modules-from-artifactory-as-dependencies">Using modules from artifactory as dependencies<a class="headerlink" href="#using-modules-from-artifactory-as-dependencies" title="Permanent link">#</a></h4>
<h5>Configure your project to use artifactory</h5>
<p>In the project which is has private modules as dependencies, add the following line to <code>.npmrc</code> in the root of the project (create this file if it does not exist).</p>
<pre><code>@&lt;namespace&gt;:registry = https://artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/
</code></pre>

<p>This will ensure that any module under that namespace will only ever install from artifactory, and never from the public registry</p>
<p>If using multiple namespaces then add a line for each namespace.</p>
<p>If the modules you are installing are not namespaced in artifactory, you can add the line with the namespace removed (i.e. <code>registry = ...</code>) but this will have a negative impact on install speed.</p>
<p>You should then add the following line to your project's <code>.npmrc</code> if they are not already there:</p>
<pre><code>//artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/:username=${NPM_AUTH_USERNAME}
//artifactory.digital.homeoffice.gov.uk/artifactory/api/npm/npm-virtual/:_password=${NPM_AUTH_TOKEN}
</code></pre>

<p>You should now be able to install modules from artifactory into your local development environment.</p>
<h4 id="installing-dependencies-in-docker">Installing dependencies in docker<a class="headerlink" href="#installing-dependencies-in-docker" title="Permanent link">#</a></h4>
<p>If you build a docker image as part of your CI pipeline, you will need to copy the <code>.npmrc</code> file into your image before installing there.</p>
<p>Example <code>Dockerfile</code>:</p>
<pre><code>FROM quay.io/ukhomeofficedigital/nodejs-base:v8

ARG NPM_AUTH_USERNAME
ARG NPM_AUTH_TOKEN

COPY .npmrc /app/.npmrc
COPY package.json /app/package.json
COPY package-lock.json /app/package-lock.json
RUN npm install --production --no-optional
COPY . /app

USER nodejs

CMD node index.js
</code></pre>

<p>When building the image, you will then need to pass the username and token variables into docker with the <code>--build-arg</code> flag.</p>
<pre><code>docker build --build-arg NPM_AUTH_USERNAME=$${NPM_AUTH_USERNAME} --build-arg NPM_AUTH_TOKEN=$${NPM_AUTH_TOKEN} .
</code></pre>

<h2 id="provisioned-volumes-and-storage-classes">Provisioned Volumes and Storage Classes<a class="headerlink" href="#provisioned-volumes-and-storage-classes" title="Permanent link">#</a></h2>
<p>In order to use volumes with your pod, we use kubernetes provisioned volume claims and storage classes, to read more about this please see <a href="https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/">Kubernetes Dynamic Provisioning</a>.</p>
<p>On each cluster in ACP, we have the the following storage classes for you to use:</p>
<pre><code>gp2-encrypted
gp2-encrypted-eu-west-2a
gp2-encrypted-eu-west-2b
gp2-encrypted-eu-west-2c
io1-encrypted-eu-west-2
io1-encrypted-eu-west-2a
io1-encrypted-eu-west-2b
io1-encrypted-eu-west-2c
st1-encrypted-eu-west-2
st1-encrypted-eu-west-2a
st1-encrypted-eu-west-2b
st1-encrypted-eu-west-2c
</code></pre>

<p>The <code>io1-*</code> (provisioned iops) storage classes have <code>iopsPerGB: "50"</code></p>
<h4 id="backups-for-ebs">Backups for EBS<a class="headerlink" href="#backups-for-ebs" title="Permanent link">#</a></h4>
<p>Once the ebs has been created, if you'd like to enable EBS snapshots for backups, please raise a ticket via the <a href="https://support.acp.homeoffice.gov.uk/servicedesk/customer/portal/1/create/96">Support Portal</a> so that we can add AWS tags to the volume, which will be picked up by <a href="https://github.com/UKHomeOffice/docker-ebs-snapshot">ebs-snapshot</a>.</p>
<h2 id="tls-passthrough">TLS Passthrough<a class="headerlink" href="#tls-passthrough" title="Permanent link">#</a></h2>
<p>There are occasions when you don't want the TLS to be terminated on the ingress and prefer to terminate in the pod instead. Note, by terminating in the pod the ingress will no longer be able to perform any L7 actions, so all of the feature set is lost (effectively it's become a TLS proxy using SNI to route the traffic)</p>
<h4 id="example-steps"><strong>Example steps</strong><a class="headerlink" href="#example-steps" title="Permanent link">#</a></h4>
<p>First create a kubernetes secret containing the certificate you wish to use.</p>
<pre><code class="shell">$ kubectl create secret tls tls --cert=cert.pem --key=cert-key.pem
</code></pre>

<p>Create the deployment and service.</p>
<pre><code class="YAML">---
apiVersion: v1
kind: Service
metadata:
  labels:
    name: tls-passthrough
  name: tls-passthrough
spec:
  type: ClusterIP
  ports:
  - name: https
    port: 443
    protocol: TCP
    targetPort: 10443
  selector:
    name: tls-passthrough
---
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: tls-passthrough
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        name: tls-passthrough
    spec:
      volumes:
      - name: certs
        secret:
          secretName: tls
      containers:
      - name: proxy
        image: quay.io/ukhomeofficedigital/nginx-proxy:v3.2.0
        ports:
        - name: https
          containerPort: 10443
          protocol: TCP
        env:
        - name: PROXY_SERVICE_HOST
          value: &quot;127.0.0.1&quot;
        - name: PROXY_SERVICE_PORT
          value: &quot;8080&quot;
        - name: SERVER_CERT
          value: /certs/tls.crt
        - name: SERVER_KEY
          value: /certs/tls.key
        - name: ENABLE_UUID_PARAM
          value: &quot;FALSE&quot;
        - name: NAXSI_USE_DEFAULT_RULES
          value: &quot;FALSE&quot;
        - name: PORT_IN_HOST_HEADER
          value: &quot;FALSE&quot;
        volumeMounts:
        - name: certs
          mountPath: /certs
          readOnly: true
      - name: fake-application
        image: kennethreitz/httpbin:latest
</code></pre>

<p>Push out the ingress resource indicating you want ssl-passthrough enabled.</p>
<pre><code class="YAML">---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;
    kubernetes.io/ingress.class: &quot;nginx-external&quot;
  name: tls-passthrough
spec:
  rules:
  - host: tls-passthrough.notprod.homeoffice.gov.uk
    http:
      paths:
      - backend:
          serviceName: tls-passthrough
          servicePort: 443
        path: /
</code></pre>

<h2 id="writing-dockerfiles">Writing Dockerfiles<a class="headerlink" href="#writing-dockerfiles" title="Permanent link">#</a></h2>
<h4 id="dockerfile-best-practice">Dockerfile best practice<a class="headerlink" href="#dockerfile-best-practice" title="Permanent link">#</a></h4>
<p>We recommend familiarising yourself with Docker's excellent <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices">guidance</a> on this topic.   </p>
<p>It is often easier to build from an existing base image. To find such base images that are maintained by Home Office colleagues, you can search the <a href="https://github.com/UKHomeOffice">UKHomeOffice organisation</a> on Github for repos starting with docker- - e.g.: <a href="https://github.com/UKHomeOffice/docker-java11-mvn">docker-java11-mvn</a></p>
<p>If you want to use a base image in the UKHomeOffice organisation that does not appear to be regularly maintained, please get in touch via the ACP Service Desk and we will arrange write access to that repo.</p>
<p>Please make sure that any base image that you maintain adheres to the best practices set out by Docker, and includes instructions to update all existing packages - e.g.:</p>
<pre><code>yum install -y curl &amp;&amp; yum clean all &amp;&amp; rpm --rebuilddb
</code></pre>

<h4 id="home-office-centos-base-image">Home Office CentOS base image<a class="headerlink" href="#home-office-centos-base-image" title="Permanent link">#</a></h4>
<p>If none of the technology specific images work for you, you can either build on top of them or build from the base <a href="https://github.com/UKHomeOffice/docker-centos-base">Centos image</a>.</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../services.html" title="Services" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Services
              </div>
            </div>
          </a>
        
        
          <a href="../developer-docs/index.html" title="Developer Getting Started Guide" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Developer Getting Started Guide
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.22b62ea4.min.js"></script>
      <script src="../assets/javascripts/bundle.5f27aba8.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.f6ebf1dc.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>